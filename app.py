from altair import Bin
from numpy import tri
import streamlit as st
import pickle
import json
import os
import random
import time
import re
import hashlib
from typing import List, Dict, Any
from streamlit_chat import message
from dotenv import load_dotenv
from datetime import datetime
from supabase_utils import init_supabase_client, update_user_profile, get_user_profile
from supabase import Client
from sympy import Rem
from PIL import Image
import io
from faster_whisper import WhisperModel
import tempfile

load_dotenv()

# Haystack imports
from haystack import Pipeline, Document
from haystack.document_stores.in_memory import InMemoryDocumentStore
from haystack.components.retrievers.in_memory import InMemoryBM25Retriever, InMemoryEmbeddingRetriever
from haystack.components.builders import PromptBuilder
from haystack.components.embedders import SentenceTransformersDocumentEmbedder, SentenceTransformersTextEmbedder

# Google AI integration - Custom Component
import google.generativeai as genai
from haystack import component, default_from_dict, default_to_dict

@component
class CustomGoogleAIGenerator:
    """
    M·ªôt component Haystack t√πy ch·ªânh ƒë·ªÉ g·ªçi tr·ª±c ti·∫øp API Gemini c·ªßa Google.
    """
    def __init__(self, api_key: str, model_name: str = "gemini-1.5-pro"):
        self.api_key = api_key
        self.model_name = model_name
        genai.configure(api_key=self.api_key)
        
        self.safety_settings = [
            {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
        ]

        self.generation_config = genai.types.GenerationConfig(
            temperature=0.2,
            max_output_tokens=1024 
        )

        self.model = genai.GenerativeModel(
            self.model_name,
            generation_config=self.generation_config,
            safety_settings=self.safety_settings 
        )


    def to_dict(self):
        return default_to_dict(self, api_key=self.api_key, model_name=self.model_name)

    @classmethod
    def from_dict(cls, data):
        return default_from_dict(cls, data)

    @component.output_types(replies=List[str])
    def run(self, prompt_parts: List[Any]): 
        """
        G·ª≠i m·ªôt prompt ƒëa ph∆∞∆°ng th·ª©c (vƒÉn b·∫£n v√† h√¨nh ·∫£nh) ƒë·∫øn API Gemini.
        """
        try:
            processed_parts = []
            for part in prompt_parts:
                if isinstance(part, bytes): 
                    try:
                        img = Image.open(io.BytesIO(part))
                        processed_parts.append(img)
                    except Exception as e:
                        print(f"L·ªói khi x·ª≠ l√Ω ·∫£nh: {e}")
                else:
                    processed_parts.append(part) 

            response = self.model.generate_content(processed_parts)
            return {"replies": [response.text]}
        except Exception as e:
            return {"replies": [f"Xin l·ªói, ƒë√£ c√≥ l·ªói x·∫£y ra khi k·∫øt n·ªëi v·ªõi m√¥ h√¨nh AI."]}

st.set_page_config(
    page_title="AI Math Tutor",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded",
    menu_items={
        'About': "Gia s∆∞ To√°n AI th√¥ng minh cho h·ªçc sinh l·ªõp 9"
    }
)

st.markdown("""
<style>
    /* Hide Streamlit branding */
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    header {visibility: hidden;}
    
    /* Main app styling */
    .main {
        padding: 1rem;
    }
    
    /* Chat container */
    .chat-container {
        max-height: 600px;
        overflow-y: auto;
        padding: 1rem;
        border-radius: 15px;
        background: linear-gradient(135deg, #2c5f7c 0%, #546e7a 100%);
        margin-bottom: 1rem;
        box-shadow: 0 8px 32px rgba(0,0,0,0.1);
    }
    
    /* User message */
    .user-message {
        background: linear-gradient(135deg, #1976d2 0%, #42a5f5 100%);
        color: white;
        padding: 12px 16px;
        border-radius: 18px 18px 4px 18px;
        margin: 8px 0;
        margin-left: 20%;
        box-shadow: 0 4px 12px rgba(25, 118, 210, 0.3);
        animation: slideInRight 0.3s ease-out;
    }
    
    /* Bot message */
    .bot-message {
        background: linear-gradient(135deg, #607d8b 0%, #78909c 100%);
        color: white;
        padding: 12px 16px;
        border-radius: 18px 18px 18px 4px;
        margin: 8px 0;
        margin-right: 20%;
        box-shadow: 0 4px 12px rgba(96, 125, 139, 0.3);
        animation: slideInLeft 0.3s ease-out;
    }
    
    /* Animations */
    @keyframes slideInRight {
        from { transform: translateX(100%); opacity: 0; }
        to { transform: translateX(0); opacity: 1; }
    }
    
    @keyframes slideInLeft {
        from { transform: translateX(-100%); opacity: 0; }
        to { transform: translateX(0); opacity: 1; }
    }
    
    @keyframes pulse {
        0%, 100% { transform: scale(1); }
        50% { transform: scale(1.05); }
    }
    
    /* Typing indicator */
    .typing-indicator {
        display: flex;
        align-items: center;
        padding: 12px 16px;
        background: rgba(255,255,255,0.1);
        border-radius: 18px;
        margin: 8px 0;
        margin-right: 20%;
        animation: pulse 2s infinite;
    }
    
    .typing-dots {
        display: flex;
        gap: 4px;
    }
    
    .typing-dot {
        width: 8px;
        height: 8px;
        border-radius: 50%;
        background: white;
        animation: typingDots 1.5s infinite;
    }
    
    .typing-dot:nth-child(2) { animation-delay: 0.3s; }
    .typing-dot:nth-child(3) { animation-delay: 0.6s; }
    
    @keyframes typingDots {
        0%, 60%, 100% { opacity: 0.3; }
        30% { opacity: 1; }
    }
    
    /* Sidebar styling */
    .sidebar .sidebar-content {
        background: linear-gradient(135deg, #2c5f7c 0%, #546e7a 100%);
        border-radius: 15px;
        padding: 1rem;
        margin: 1rem 0;
    }
    
    /* Input styling - Fix pink outline issue */
    .stTextInput > div > div > input {
        border-radius: 25px !important;
        border: 2px solid #1976d2 !important;
        padding: 12px 20px;
        font-size: 16px;
        transition: all 0.3s ease;
        outline: none !important;
        box-shadow: none !important;
    }
    
    .stTextInput > div > div > input:focus {
        border-color: #42a5f5 !important;
        box-shadow: 0 0 20px rgba(66, 165, 245, 0.3) !important;
        outline: none !important;
    }
    
    /* Remove default Streamlit input container styling */
    .stTextInput > div {
        border: none !important;
        background: transparent !important;
    }
    
    .stTextInput {
        background: transparent !important;
    }
    
    /* Button styling */
    .stButton > button {
        border-radius: 25px;
        border: none;
        background: linear-gradient(135deg, #1976d2 0%, #42a5f5 100%);
        color: white;
        padding: 12px 24px;
        font-weight: 600;
        transition: all 0.3s ease;
        box-shadow: 0 4px 12px rgba(25, 118, 210, 0.3);
    }
    
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 6px 16px rgba(25, 118, 210, 0.4);
    }
    
    /* Welcome message */
    .welcome-message {
        text-align: center;
        padding: 2rem;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        border-radius: 20px;
        color: white;
        margin: 2rem 0;
        box-shadow: 0 8px 32px rgba(0,0,0,0.1);
    }
    
    /* Feature cards */
    .feature-card {
        background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
        border-radius: 15px;
        padding: 1.5rem;
        margin: 1rem 0;
        color: white;
        box-shadow: 0 4px 12px rgba(240, 147, 251, 0.3);
        transition: transform 0.3s ease;
    }
    
    .feature-card:hover {
        transform: translateY(-5px);
    }
    
    /* Status indicators */
    .status-online {
        color: #4ade80;
        font-weight: 600;
    }
    
    .status-thinking {
        color: #fbbf24;
        font-weight: 600;
    }
    
    /* Math expression styling */
    .math-expression {
        background: rgba(255,255,255,0.1);
        padding: 8px 12px;
        border-radius: 8px;
        font-family: 'Courier New', monospace;
        margin: 4px 0;
    }
</style>
""", unsafe_allow_html=True)

# Ki·ªÉm tra API key
if "GOOGLE_API_KEY" not in os.environ:
    st.error("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y API key. Vui l√≤ng c·∫•u h√¨nh bi·∫øn m√¥i tr∆∞·ªùng.")
    st.stop()

@st.cache_resource
def load_resources():
    """Load v√† kh·ªüi t·∫°o t·∫•t c·∫£ t√†i nguy√™n c·ªßa h·ªá th·ªëng"""
    
    # Load documents
    try:
        with open("embedded_documents.pkl", "rb") as f:
            documents = pickle.load(f)
    except FileNotFoundError:
        st.error("‚ùå Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu h·ªçc li·ªáu")
        st.stop()
    
    # Load videos
    try:
        with open("videos.json", "r", encoding="utf-8") as f:
            videos_data = json.load(f)
    except FileNotFoundError:
        st.error("‚ùå Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu video")
        st.stop()
    
    # Initialize document store
    document_store = InMemoryDocumentStore()
    document_store.write_documents(documents)
    
    # Initialize components
    retriever = InMemoryEmbeddingRetriever(document_store=document_store)
    text_embedder = SentenceTransformersTextEmbedder(
        model="bkai-foundation-models/vietnamese-bi-encoder"
    )

    print("DEBUG: Loading Faster Whisper model...")
    model_size = "small" 

    # Ch·∫°y tr√™n CPU v·ªõi INT8 ƒë·ªÉ t·ªëi ∆∞u
    whisper_model = WhisperModel(model_size, device="cpu", compute_type="int8")

    print(f"DEBUG: Faster Whisper model '{model_size}' loaded successfully.")
    
    # Templates
    informer_template = """
        B·∫°n l√† m·ªôt Gia s∆∞ To√°n AI chuy√™n nghi·ªáp. Vai tr√≤ c·ªßa b·∫°n l√† cung c·∫•p m·ªôt l·ªùi gi·∫£i ho·∫∑c m·ªôt l·ªùi gi·∫£i th√≠ch chi ti·∫øt, ch√≠nh x√°c v√† d·ªÖ hi·ªÉu cho h·ªçc sinh l·ªõp 9.

        **QUY TR√åNH C·ª¶A B·∫†N:**
        1.  **ƒê·ªçc L·ªãch s·ª≠ Tr√≤ chuy·ªán:** Hi·ªÉu r√µ b·ªëi c·∫£nh v√† c√¢u h·ªèi tr∆∞·ªõc ƒë√≥ c·ªßa h·ªçc sinh.
        2.  **Nghi√™n c·ª©u T√†i li·ªáu:** Tham kh·∫£o k·ªπ c√°c th√¥ng tin t·ª´ s√°ch gi√°o khoa ƒë∆∞·ª£c cung c·∫•p.
        3.  **Tr·∫£ l·ªùi c√¢u h·ªèi cu·ªëi c√πng:** D·ª±a v√†o c·∫£ l·ªãch s·ª≠ v√† t√†i li·ªáu, h√£y tr·∫£ l·ªùi c√¢u h·ªèi cu·ªëi c√πng c·ªßa h·ªçc sinh.

        **Y√äU C·∫¶U TR√åNH B√ÄY:**
        -   S·ª≠ d·ª•ng ng√¥n ng·ªØ s∆∞ ph·∫°m, r√µ r√†ng, t·ª´ng b∆∞·ªõc m·ªôt.
        -   S·ª≠ d·ª•ng Markdown ƒë·ªÉ ƒë·ªãnh d·∫°ng c√°c c√¥ng th·ª©c to√°n h·ªçc, c√°c ƒë·ªÅ m·ª•c v√† nh·∫•n m·∫°nh c√°c ƒëi·ªÉm quan tr·ªçng.
        -   Lu√¥n tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát.

        ---
        **L·ªäCH S·ª¨ TR√í CHUY·ªÜN G·∫¶N ƒê√ÇY:**
        {{ conversation_history }}
        ---
        **TH√îNG TIN S√ÅCH GI√ÅO KHOA (T·ª™ RAG):**
        {% for doc in documents %}
        {{ doc.content }}
        {% endfor %}
        ---

        **C√¢u h·ªèi cu·ªëi c√πng c·ªßa h·ªçc sinh:** {{ query }}

        **L·ªùi gi·∫£i chi ti·∫øt c·ªßa b·∫°n:**
        """

    practice_template = """
        B·∫°n l√† m·ªôt chuy√™n gia ra ƒë·ªÅ thi v√† t∆∞ v·∫•n h·ªçc li·ªáu m√¥n To√°n.

        **NHI·ªÜM V·ª§:**
        D·ª±a tr√™n **ch·ªß ƒë·ªÅ y·∫øu** c·ªßa h·ªçc sinh v√† **danh s√°ch video** ƒë∆∞·ª£c cung c·∫•p, h√£y th·ª±c hi·ªán 2 vi·ªác:

        1.  **T·∫°o 2 B√†i t·∫≠p M·ªõi:**
            -   C√°c b√†i t·∫≠p ph·∫£i li√™n quan tr·ª±c ti·∫øp ƒë·∫øn ch·ªß ƒë·ªÅ y·∫øu.
            -   ƒê·ªô kh√≥ t∆∞∆°ng ƒë∆∞∆°ng ch∆∞∆°ng tr√¨nh l·ªõp 9.
            -   B√†i t·∫≠p ph·∫£i ho√†n to√†n m·ªõi, kh√¥ng ƒë∆∞·ª£c tr√πng l·∫∑p v·ªõi c√°c v√≠ d·ª• ph·ªï bi·∫øn.
        2.  **ƒê·ªÅ xu·∫•t 1 Video Ph√π h·ª£p nh·∫•t:**
            -   Ch·ªçn ra M·ªòT video t·ª´ danh s√°ch c√≥ n·ªôi dung li√™n quan ch·∫∑t ch·∫Ω nh·∫•t ƒë·∫øn ch·ªß ƒë·ªÅ y·∫øu.

        **TH√îNG TIN ƒê·∫¶U V√ÄO:**
        -   **Ch·ªß ƒë·ªÅ y·∫øu c·ªßa h·ªçc sinh:** '{{ student_weakness }}'
        -   **Danh s√°ch video c√≥ s·∫µn (JSON):** {{ video_cheatsheet_json }}

        **Y√äU C·∫¶U OUTPUT:**
        Ch·ªâ tr·∫£ l·ªùi theo ƒë·ªãnh d·∫°ng Markdown d∆∞·ªõi ƒë√¢y, kh√¥ng th√™m b·∫•t k·ª≥ l·ªùi d·∫´n hay gi·∫£i th√≠ch n√†o kh√°c.

        ### üéØ B√ÄI T·∫¨P C·ª¶NG C·ªê
        1.  **B√†i 1:** [N·ªôi dung c√¢u h·ªèi b√†i t·∫≠p 1]
        2.  **B√†i 2:** [N·ªôi dung c√¢u h·ªèi b√†i t·∫≠p 2]


        ### üìπ VIDEO ƒê·ªÄ XU·∫§T
        **[T√™n video]**
        üé¨ Link: https://www.youtube.com/playlist?list=PL5q2T2FxzK7XY4s9FqDi6KCFEpGr2LX2D"""

    insight_template = """
        B·∫°n l√† m·ªôt chuy√™n gia ph√¢n t√≠ch gi√°o d·ª•c. Nhi·ªám v·ª• c·ªßa b·∫°n l√† ƒë·ªçc k·ªπ ƒëo·∫°n h·ªôi tho·∫°i v√† x√°c ƒë·ªãnh ch√≠nh x√°c nh·ªØng kh√°i ni·ªám to√°n h·ªçc m√† h·ªçc sinh ƒëang hi·ªÉu sai.

        **H∆Ø·ªöNG D·∫™N:**
        - ƒê·ªçc k·ªπ to√†n b·ªô h·ªôi tho·∫°i.
        - T·∫≠p trung v√†o nh·ªØng c√¢u h·ªèi ho·∫∑c nh·∫≠n ƒë·ªãnh c·ªßa 'User' th·ªÉ hi·ªán s·ª± nh·∫ßm l·∫´n ho·∫∑c thi·∫øu ki·∫øn th·ª©c.
        - D·ª±a tr√™n s·ª± nh·∫ßm l·∫´n ƒë√≥, x√°c ƒë·ªãnh kh√°i ni·ªám to√°n h·ªçc c·ªët l√µi b·ªã hi·ªÉu sai.
        - Ch·ªâ tr·∫£ l·ªùi b·∫±ng m·ªôt ƒë·ªëi t∆∞·ª£ng JSON duy nh·∫•t theo ƒë·ªãnh d·∫°ng sau. Kh√¥ng th√™m b·∫•t k·ª≥ gi·∫£i th√≠ch hay vƒÉn b·∫£n n√†o kh√°c.

        **V√ç D·ª§:**
        ---
        H·ªôi tho·∫°i:
        User: h·ªá th·ª©c Vi-√©t d√πng ƒë·ªÉ l√†m g√¨?
        Assistant: ...
        User: v·∫≠y n·∫øu ph∆∞∆°ng tr√¨nh v√¥ nghi·ªám th√¨ v·∫´n t√≠nh t·ªïng v√† t√≠ch c√°c nghi·ªám ƒë∆∞·ª£c ƒë√∫ng kh√¥ng?
        ---
        JSON Output:
        {"misunderstood_concepts": ["ƒëi·ªÅu ki·ªán √°p d·ª•ng h·ªá th·ª©c Vi-√©t"], "sentiment": "confused"}
        ---

        **B√ÇY GI·ªú, H√ÉY PH√ÇN T√çCH H·ªòI THO·∫†I SAU:**

        **H·ªôi tho·∫°i:**
        {{ conversation_history }}

        **JSON Output:**
        """

    verifier_template = """Bin l√† m·ªôt ng∆∞·ªùi ki·ªÉm ƒë·ªãnh ch·∫•t l∆∞·ª£ng to√°n h·ªçc c·ª±c k·ª≥ kh√≥ t√≠nh v√† ch√≠nh x√°c.
        Nhi·ªám v·ª• c·ªßa b·∫°n l√† ki·ªÉm tra xem l·ªùi gi·∫£i ƒë∆∞·ª£c ƒë·ªÅ xu·∫•t c√≥ ho√†n to√†n ƒë√∫ng v·ªÅ m·∫∑t to√°n h·ªçc v√† logic hay kh√¥ng.

        **C√¢u h·ªèi c·ªßa h·ªçc sinh:** {{ query }}

        **L·ªùi gi·∫£i ƒë∆∞·ª£c ƒë·ªÅ xu·∫•t:** {{ informer_answer }}

        **Y√äU C·∫¶U:**
        H√£y ki·ªÉm tra t·ª´ng b∆∞·ªõc, t·ª´ng c√¥ng th·ª©c v√† k·∫øt qu·∫£ cu·ªëi c√πng. Sau ƒë√≥, ch·ªâ tr·∫£ l·ªùi b·∫±ng m·ªôt ƒë·ªëi t∆∞·ª£ng JSON duy nh·∫•t theo ƒë·ªãnh d·∫°ng sau.

        **JSON Output:**
        {"is_correct": [true ho·∫∑c false], "correction_suggestion": "[N·∫øu sai, h√£y gi·∫£i th√≠ch ng·∫Øn g·ªçn v√† ch√≠nh x√°c l·ªói sai n·∫±m ·ªü ƒë√¢u. N·∫øu ƒë√∫ng, ƒë·ªÉ tr·ªëng chu·ªói n√†y.]"}
        """

    intent_template = """
        B·∫°n l√† m·ªôt h·ªá th·ªëng ph√¢n lo·∫°i √Ω ƒë·ªãnh c·ª±c k·ª≥ ch√≠nh x√°c. D·ª±a v√†o c√¢u h·ªèi cu·ªëi c√πng c·ªßa ng∆∞·ªùi d√πng, h√£y ph√¢n lo·∫°i n√≥ v√†o M·ªòT trong c√°c lo·∫°i sau.

        **ƒê·ªäNH NGHƒ®A C√ÅC LO·∫†I:**
        - 'greeting_social': Ch√†o h·ªèi, x√£ giao, c·∫£m ∆°n, t·∫°m bi·ªát.
        - 'math_question': B·∫•t k·ª≥ c√¢u h·ªèi n√†o li√™n quan tr·ª±c ti·∫øp ƒë·∫øn ki·∫øn th·ª©c to√°n h·ªçc, bao g·ªìm gi·∫£i b√†i t·∫≠p, t√≠nh to√°n, h·ªèi ƒë·ªãnh nghƒ©a, h·ªèi c√¥ng th·ª©c, h·ªèi t√≠nh ch·∫•t.
        - 'request_for_practice': Y√™u c·∫ßu b√†i t·∫≠p luy·ªán t·∫≠p, mu·ªën th·ª±c h√†nh.
        - 'expression_of_stress': Bi·ªÉu hi·ªán cƒÉng th·∫≥ng, m·ªát m·ªèi, n·∫£n l√≤ng.
        - 'study_support': H·ªèi v·ªÅ ph∆∞∆°ng ph√°p h·ªçc chung, c√°ch ƒë·ªÉ ti·∫øn b·ªô, t√¨m ki·∫øm ƒë·ªông l·ª±c.
        - 'off_topic': Ch·ªß ƒë·ªÅ ho√†n to√†n kh√¥ng li√™n quan ƒë·∫øn h·ªçc t·∫≠p.

        **V√ç D·ª§:**
        ---
        User: Ch√†o b·∫°n
        Ph√¢n lo·∫°i: greeting_social
        ---
        User: Gi·∫£i gi√∫p m√¨nh ph∆∞∆°ng tr√¨nh x^2 + 5x - 6 = 0
        Ph√¢n lo·∫°i: math_question
        ---
        User: h·ªá th·ª©c Vi-√©t d√πng ƒë·ªÉ l√†m g√¨?  <-- V√ç D·ª§ M·ªöI QUAN TR·ªåNG
        Ph√¢n lo·∫°i: math_question
        ---
        User: B√†i n√†y kh√≥ qu√°, m√¨nh n·∫£n th·∫≠t
        Ph√¢n lo·∫°i: expression_of_stress
        ---
        User: C√≥ b√†i n√†o t∆∞∆°ng t·ª± ƒë·ªÉ m√¨nh luy·ªán t·∫≠p th√™m kh√¥ng?
        Ph√¢n lo·∫°i: request_for_practice
        ---
        User: L√†m sao ƒë·ªÉ h·ªçc t·ªët m√¥n h√¨nh h·ªçc kh√¥ng gian?
        Ph√¢n lo·∫°i: study_support
        ---
        User: Gi√° v√†ng h√¥m nay bao nhi√™u?
        Ph√¢n lo·∫°i: off_topic
        ---

        **B√¢y gi·ªù, h√£y ph√¢n lo·∫°i l·ªãch s·ª≠ chat sau. Ch·ªâ tr·∫£ v·ªÅ M·ªòT t·ª´ duy nh·∫•t.**

        **L·ªãch s·ª≠ chat:**
        {{ conversation_history }}

        **Ph√¢n lo·∫°i:**
        """

    # --- TEMPLATES CHO TUTOR AGENT ---

    # Prompt t·ªïng qu√°t ƒë·ªãnh h√¨nh vai tr√≤ v√† t√≠nh c√°ch
    tutor_master_prompt = """
    B·∫°n l√† m·ªôt Gia s∆∞ To√°n AI, m·ªôt ng∆∞·ªùi b·∫°n ƒë·ªìng h√†nh h·ªçc t·∫≠p th√¥ng minh, th·∫•u c·∫£m v√† chuy√™n nghi·ªáp.
    Vai tr√≤ c·ªßa b·∫°n l√† ph·∫£n h·ªìi l·∫°i h·ªçc sinh m·ªôt c√°ch ph√π h·ª£p nh·∫•t d·ª±a tr√™n √Ω ƒë·ªãnh c·ªßa h·ªç.
    Lu√¥n s·ª≠ d·ª•ng ng√¥n ng·ªØ t√≠ch c·ª±c, khuy·∫øn kh√≠ch v√† th√¢n thi·ªán. Lu√¥n tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát.
    """

    # Prompt cho intent 'greeting_social'
    greeting_template = """
    {{ master_prompt }}

    **B·ªëi c·∫£nh:** H·ªçc sinh ƒëang b·∫Øt ƒë·∫ßu cu·ªôc tr√≤ chuy·ªán ho·∫∑c n√≥i nh·ªØng c√¢u x√£ giao (ch√†o h·ªèi, c·∫£m ∆°n).
    **Nhi·ªám v·ª•:** H√£y ph·∫£n h·ªìi l·∫°i m·ªôt c√°ch th√¢n thi·ªán, t·ª± nhi√™n v√† m·ªùi g·ªçi h·ªç b·∫Øt ƒë·∫ßu bu·ªïi h·ªçc.

    **L·ªãch s·ª≠ chat g·∫ßn ƒë√¢y:**
    {{ conversation_history }}

    **L·ªùi ch√†o th√¢n thi·ªán c·ªßa b·∫°n:**
    """

    # Prompt cho intent 'expression_of_stress'
    stress_template = """
    {{ master_prompt }}

    **B·ªëi c·∫£nh:** H·ªçc sinh ƒëang th·ªÉ hi·ªán s·ª± cƒÉng th·∫≥ng, m·ªát m·ªèi ho·∫∑c n·∫£n l√≤ng v·ªÅ vi·ªác h·ªçc.
    **NHI·ªÜM V·ª§ C·ª∞C K·ª≤ QUAN TR·ªåNG:**
    1.  **ƒê·ªìng c·∫£m:** Th·ªÉ hi·ªán r·∫±ng b·∫°n hi·ªÉu c·∫£m gi√°c c·ªßa h·ªç.
    2.  **B√¨nh th∆∞·ªùng h√≥a:** Cho h·ªç bi·∫øt r·∫±ng c·∫£m gi√°c n√†y l√† b√¨nh th∆∞·ªùng.
    3.  **G·ª£i √Ω gi·∫£i ph√°p AN TO√ÄN:** ƒê·ªÅ xu·∫•t nh·ªØng h√†nh ƒë·ªông ƒë∆°n gi·∫£n nh∆∞ ngh·ªâ ng∆°i, h√≠t th·ªü s√¢u.
    4.  **TUY·ªÜT ƒê·ªêI KH√îNG:** ƒê√≥ng vai chuy√™n gia t√¢m l√Ω, kh√¥ng ƒë∆∞a ra l·ªùi khuy√™n ph·ª©c t·∫°p.

    **L·ªãch s·ª≠ chat g·∫ßn ƒë√¢y:**
    {{ conversation_history }}

    **L·ªùi ƒë·ªông vi√™n an to√†n v√† th·∫•u c·∫£m c·ªßa b·∫°n:**
    """

    # Prompt cho intent 'study_support'
    support_template = """
    {{ master_prompt }}

    **B·ªëi c·∫£nh:** H·ªçc sinh ƒëang h·ªèi v·ªÅ ph∆∞∆°ng ph√°p h·ªçc t·∫≠p, c√°ch ƒë·ªÉ ti·∫øn b·ªô ho·∫∑c t√¨m ki·∫øm ƒë·ªông l·ª±c.
    **Nhi·ªám v·ª•:** H√£y ƒë∆∞a ra nh·ªØng l·ªùi khuy√™n chung, h·ªØu √≠ch v√† mang t√≠nh ƒë·ªông vi√™n v·ªÅ vi·ªác h·ªçc To√°n. B·∫°n c√≥ th·ªÉ g·ª£i √Ω v·ªÅ c√°c ch·ª©c nƒÉng c·ªßa m√¨nh (gi·∫£i b√†i t·∫≠p, t·∫°o luy·ªán t·∫≠p,...).

    **L·ªãch s·ª≠ chat g·∫ßn ƒë√¢y:**
    {{ conversation_history }}

    **L·ªùi khuy√™n v√† h·ªó tr·ª£ c·ªßa b·∫°n:**
    """

    # Prompt cho intent 'off_topic'
    off_topic_template = """
    {{ master_prompt }}

    **B·ªëi c·∫£nh:** H·ªçc sinh ƒëang h·ªèi m·ªôt c√¢u ho√†n to√†n kh√¥ng li√™n quan ƒë·∫øn to√°n h·ªçc ho·∫∑c h·ªçc t·∫≠p.
    **Nhi·ªám v·ª•:** H√£y l·ªãch s·ª± t·ª´ ch·ªëi tr·∫£ l·ªùi v√† nh·∫π nh√†ng h∆∞·ªõng cu·ªôc tr√≤ chuy·ªán quay tr·ªü l·∫°i ch·ªß ƒë·ªÅ ch√≠nh l√† h·ªçc To√°n.

    **L·ªãch s·ª≠ chat g·∫ßn ƒë√¢y:**
    {{ conversation_history }}

    **L·ªùi t·ª´ ch·ªëi kh√©o l√©o c·ªßa b·∫°n:**
    """

    # Create prompt builders
    informer_prompt_builder = PromptBuilder(template=informer_template, required_variables=["documents", "query", "conversation_history"])
    practice_prompt_builder = PromptBuilder(template=practice_template, required_variables=["student_weakness", "video_cheatsheet_json"])
    insight_prompt_builder = PromptBuilder(template=insight_template, required_variables=["conversation_history"])
    verifier_prompt_builder = PromptBuilder(template=verifier_template, required_variables=["query", "informer_answer"])
    intent_prompt_builder = PromptBuilder(template=intent_template, required_variables=["conversation_history"])
    
    greeting_prompt_builder = PromptBuilder(template=greeting_template, required_variables=["master_prompt", "conversation_history"])
    stress_prompt_builder = PromptBuilder(template=stress_template, required_variables=["master_prompt", "conversation_history"])
    support_prompt_builder = PromptBuilder(template=support_template, required_variables=["master_prompt", "conversation_history"])
    off_topic_prompt_builder = PromptBuilder(template=off_topic_template, required_variables=["master_prompt", "conversation_history"])
    
    # Create generator
    generator = CustomGoogleAIGenerator(api_key=os.getenv("GOOGLE_API_KEY"))
    
    return {
        "informer_prompt_builder": informer_prompt_builder,
        "generator": generator,
        "practice_prompt_builder": practice_prompt_builder,
        "insight_prompt_builder": insight_prompt_builder,
        "verifier_prompt_builder": verifier_prompt_builder,
        "intent_prompt_builder": intent_prompt_builder,
        "videos_data": videos_data,
        "document_store": document_store,
        "tutor_master_prompt": tutor_master_prompt,
        "greeting_prompt_builder": greeting_prompt_builder,
        "stress_prompt_builder": stress_prompt_builder,
        "support_prompt_builder": support_prompt_builder,
        "off_topic_prompt_builder": off_topic_prompt_builder,
        "retriever": retriever,
        "text_embedder": text_embedder,
        "whisper_model": whisper_model
    }

def transcribe_audio(audio_file, whisper_model: WhisperModel) -> str:
    """
    Nh·∫≠n audio file t·ª´ st.audio_input v√† chuy·ªÉn ƒë·ªïi th√†nh vƒÉn b·∫£n b·∫±ng Faster Whisper.
    Phi√™n b·∫£n ƒë∆∞·ª£c c·∫≠p nh·∫≠t cho m√¥i tr∆∞·ªùng deployment.
    """
    if not audio_file:
        return ""
        
    tmp_file_path = ""
    try:
        # ƒê·ªçc audio file t·ª´ st.audio_input (UploadedFile object)
        audio_bytes = audio_file.read()
        
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmpfile:
            tmpfile.write(audio_bytes)
            tmp_file_path = tmpfile.name
        
        print(f"DEBUG: [Whisper] Audio saved to temp file: {tmp_file_path}")
        
        print(f"DEBUG: [Whisper] Transcribing audio from: {tmp_file_path}")
        segments, info = whisper_model.transcribe(tmp_file_path, beam_size=5, language="vi")

        print(f"DEBUG: [Whisper] Detected language: {info.language} with probability {info.language_probability}")
        
        transcribed_text = " ".join(segment.text for segment in segments)
        print(f"DEBUG: [Whisper] Transcribed text: '{transcribed_text}'")
        return transcribed_text.strip()
            
    except Exception as e:
        st.error(f"L·ªói khi x·ª≠ l√Ω gi·ªçng n√≥i: {e}")
        return ""
    finally:
        if tmp_file_path and os.path.exists(tmp_file_path):
            os.remove(tmp_file_path)
            print(f"DEBUG: [Whisper] Cleaned up temp file: {tmp_file_path}")


def classify_intent(conversation_history: str, resources: Dict) -> str:
    """Ph√¢n lo·∫°i √Ω ƒë·ªãnh ng∆∞·ªùi d√πng"""
    valid_intents = ['greeting_social', 'math_question', 'request_for_practice', 'expression_of_stress', 'study_support', 'off_topic']
    
    try:
        prompt_builder = resources["intent_prompt_builder"]
        
        prompt_text = prompt_builder.run(conversation_history=conversation_history)["prompt"]
        
        result = resources["generator"].run(prompt_parts=[prompt_text])
        intent = result["replies"][0].strip().lower()
        
        user_input_debug = "N/A"
        if 'User: ' in conversation_history: 
            lines = conversation_history.split('\n')
            for line in reversed(lines):
                if line.strip().startswith('User: '): 
                    user_input_debug = line.replace('User: ', '').strip()
                    break
        
        print(f"DEBUG - User input: {user_input_debug}")
        print(f"DEBUG - Classified intent: {intent}")
        
        if intent not in valid_intents:
            math_keywords = ['gi·∫£i', 't√≠nh', 'ph∆∞∆°ng tr√¨nh', 'b√†i t·∫≠p', 'to√°n', 'x√°c su·∫•t', 'th·ªëng k√™', 'h√¨nh h·ªçc', 'ƒë·∫°i s·ªë']
            
            user_input_for_fallback = "N/A"
            if 'User: ' in conversation_history:
                lines = conversation_history.split('\n')
                for line in reversed(lines):
                    if line.strip().startswith('User: '):
                        user_input_for_fallback = line.replace('User: ', '').strip()
                        break
            
            if any(keyword in user_input_for_fallback.lower() for keyword in math_keywords):
                intent = 'math_question'
            else:
                intent = 'greeting_social'
        
        return intent
    except Exception as e:
        print(f"DEBUG - Intent classification error: {e}")
        return 'greeting_social'

def informer_agent(query: str, conversation_history_str: str, resources: Dict) -> str:
    """Agent gi·∫£i to√°n d·ª±a tr√™n RAG"""
    try:
        result = resources["informer_pipeline"].run({
            "text_embedder": {"text": query},
            "prompt_builder": {"query": query, "conversation_history": conversation_history_str}
        })
        return result["generator"]["replies"][0]
    except:
        return "Xin l·ªói, t√¥i kh√¥ng th·ªÉ gi·∫£i b√†i n√†y l√∫c n√†y."

def verifier_agent(query: str, informer_answer: str, resources: Dict) -> Dict:
    """Agent ki·ªÉm tra t√≠nh ƒë√∫ng ƒë·∫Øn"""
    try:
        prompt_text = resources["verifier_prompt_builder"].run(query=query, informer_answer=informer_answer)["prompt"]
        result = resources["generator"].run(prompt_parts=[prompt_text])
        llm_reply_string = result["replies"][0]

        json_match = re.search(r"\{.*\}", llm_reply_string, re.DOTALL)
        if json_match:
            return json.loads(json_match.group(0))
        else:
            return {"is_correct": True, "correction_suggestion": "L·ªói parse verifier"}
    except Exception as e:
        print(f"ERROR: [Verifier Agent] L·ªói: {e}")
        return {"is_correct": True, "correction_suggestion": ""}

def insight_agent(conversation_history: str, resources: Dict) -> Dict:
    """Agent ph√¢n t√≠ch ƒëi·ªÉm y·∫øu, v·ªõi logic tr√≠ch xu·∫•t JSON th√¥ng minh."""
    try:
        prompt_builder = resources["insight_prompt_builder"]
        prompt_text = prompt_builder.run(conversation_history=conversation_history)["prompt"]
        
        print("\n" + "="*50)
        print(prompt_text)
        print("="*50 + "\n")

        result = resources["generator"].run(prompt_parts=[prompt_text])
        llm_reply = result["replies"][0]

        json_match = re.search(r"\{.*\}", llm_reply, re.DOTALL)
        
        if json_match:
            json_string = json_match.group(0)
            return json.loads(json_string)
        else:
            return {"misunderstood_concepts": [], "sentiment": "neutral"}

    except json.JSONDecodeError as e:
        return {"misunderstood_concepts": [], "sentiment": "neutral"}
    except Exception as e:
        return {"misunderstood_concepts": [], "sentiment": "neutral"}

def practice_agent(student_weakness: str, resources: Dict) -> str:
    """Agent t·∫°o b√†i t·∫≠p"""
    try:
        video_cheatsheet = []
        for video in resources["videos_data"]:
            video_cheatsheet.append({
                "title": video["title"],
                "keywords": video["keywords"],
                "summary": video["summary_for_llm"]
            })
        
        video_json = json.dumps(video_cheatsheet, ensure_ascii=False)
        prompt_text = resources["practice_prompt_builder"].run(
            student_weakness=student_weakness,
            video_cheatsheet_json=video_json
        )["prompt"]
        
        result = resources["generator"].run(prompt_parts=[prompt_text])
        return result["replies"][0]
    except:
        return "Xin l·ªói, t√¥i kh√¥ng th·ªÉ t·∫°o b√†i t·∫≠p l√∫c n√†y."

def problem_solving_engine(
    query_text: str, 
    query_image: bytes, 
    conversation_history_str: str, 
    resources: Dict
) -> str:
    """
    C·ªó m√°y gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ ƒëa nƒÉng, T√ÅI S·ª¨ D·ª§NG informer_prompt_builder.
    """
    print("DEBUG: Multimodal Problem-Solving Engine activated.")
    
    try:
        extracted_text_from_image = ""
        if query_image:
            print("DEBUG: [Stage 1] Image detected. Calling Gemini for OCR...")
            try:
                ocr_prompt_parts = [
                    "B·∫°n l√† m·ªôt h·ªá th·ªëng OCR to√°n h·ªçc si√™u ch√≠nh x√°c. H√£y ƒë·ªçc v√† tr√≠ch xu·∫•t to√†n b·ªô vƒÉn b·∫£n t·ª´ h√¨nh ·∫£nh sau ƒë√¢y. Ch·ªâ tr·∫£ v·ªÅ ph·∫ßn vƒÉn b·∫£n ƒë∆∞·ª£c tr√≠ch xu·∫•t.", 
                    query_image
                ]
                ocr_result = resources["generator"].run(prompt_parts=ocr_prompt_parts)
                extracted_text_from_image = ocr_result["replies"][0]
                print(f"DEBUG: [Stage 1] Text extracted from image: '{extracted_text_from_image}'")
            except Exception as e:
                print(f"ERROR: [Stage 1] OCR failed: {e}")
                extracted_text_from_image = "Kh√¥ng th·ªÉ ƒë·ªçc ƒë∆∞·ª£c n·ªôi dung t·ª´ h√¨nh ·∫£nh."

        full_query_text = (query_text + " " + extracted_text_from_image).strip()
        print(f"DEBUG: [Stage 1.5] Full query text: '{full_query_text}'")

        context_docs = []
        if full_query_text:
            try:
                print("DEBUG: [Stage 2] Starting RAG retrieval...")
                embedding = resources["text_embedder"].run(text=full_query_text)["embedding"]
                print("DEBUG: [Stage 2] Embedding created successfully")
                context_docs = resources["retriever"].run(query_embedding=embedding)["documents"]
                print(f"DEBUG: [Stage 2] Retrieved {len(context_docs)} documents")
            except Exception as e:
                print(f"ERROR: [Stage 2] RAG retrieval failed: {e}")
                context_docs = []

        print("DEBUG: [Stage 3] Building final prompt...")
        
        try:
            informer_prompt_builder = resources["informer_prompt_builder"]
            print("DEBUG: [Stage 3a] Got informer_prompt_builder")
            
            text_prompt_result = informer_prompt_builder.run(
                query=query_text if query_text else "Gi·∫£i b√†i to√°n trong h√¨nh.",
                conversation_history=conversation_history_str,
                documents=context_docs
            )
            print("DEBUG: [Stage 3a] Prompt builder ran successfully")
            
            text_part = text_prompt_result["prompt"]
            print(f"DEBUG: [Stage 3a] Generated text prompt length: {len(text_part)} chars")
            
        except Exception as e:
            print(f"ERROR: [Stage 3a] Prompt building failed: {e}")
            # Fallback to simple prompt
            text_part = f"""B·∫°n l√† gia s∆∞ to√°n AI. H√£y gi·∫£i b√†i to√°n sau:

                C√¢u h·ªèi: {query_text if query_text else "Gi·∫£i b√†i to√°n trong h√¨nh"}
                N·ªôi dung t·ª´ h√¨nh: {extracted_text_from_image}

                L·ªãch s·ª≠: {conversation_history_str}

                H√£y tr·∫£ l·ªùi chi ti·∫øt b·∫±ng ti·∫øng Vi·ªát:"""

        final_prompt_parts = [text_part]
        
        if query_image:
            final_prompt_parts.append("\n**H√¨nh ·∫£nh ƒë√≠nh k√®m:**")
            final_prompt_parts.append(query_image)
            
        print(f"DEBUG: [Stage 3b] Final prompt parts count: {len(final_prompt_parts)}")
            
        print("DEBUG: [Stage 4] Calling Gemini for final answer...")
        try:
            final_result = resources["generator"].run(prompt_parts=final_prompt_parts)
            informer_answer = final_result["replies"][0]
            print(f"DEBUG: [Stage 4] Got answer, length: {len(informer_answer)} chars")
        except Exception as e:
            print(f"ERROR: [Stage 4] Gemini call failed: {e}")
            return f"Xin l·ªói, t√¥i kh√¥ng th·ªÉ x·ª≠ l√Ω c√¢u h·ªèi n√†y l√∫c n√†y. L·ªói: {str(e)}"

        try:
            print("DEBUG: [Stage 5] Starting verification...")
            verification_query = full_query_text if full_query_text else "Ph√¢n t√≠ch b√†i to√°n trong h√¨nh ·∫£nh"
            verification = verifier_agent(verification_query, informer_answer, resources)
            print(f"DEBUG: [Stage 5] Verification result: {verification}")
            
            if verification.get("is_correct", True):
                return informer_answer
            else:
                correction = verification.get("correction_suggestion", "")
                return f"üîç T√¥i ƒë√£ xem x√©t l·∫°i v√† th·∫•y c√≥ m·ªôt ch√∫t ch∆∞a ch√≠nh x√°c. {correction}"
        except Exception as e:
            print(f"ERROR: [Stage 5] Verification failed: {e}")
            return informer_answer

    except Exception as e:
        print(f"ERROR: [Problem-Solving Engine] Critical error: {str(e)}")
        import traceback
        print(f"ERROR: [Problem-Solving Engine] Traceback: {traceback.format_exc()}")
        return f"Xin l·ªói, ƒë√£ c√≥ l·ªói nghi√™m tr·ªçng khi x·ª≠ l√Ω y√™u c·∫ßu: {str(e)}"


def tutor_agent_response(user_input: str, intent: str, conversation_history_str: str, resources: Dict, supabase: Client, user_id: str, display_name: str) -> str:
    """
    Agent ch√≠nh, b√¢y gi·ªù CH·ªà x·ª≠ l√Ω c√°c intent giao ti·∫øp.
    C√°c c√¢u h·ªèi to√°n h·ªçc ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω b·ªüi problem_solving_engine.
    """
    print(f"DEBUG: Tutor Agent is handling a communication intent: '{intent}'")
    
    if intent == "greeting_social":
        prompt_builder = resources["greeting_prompt_builder"]
    elif intent == "expression_of_stress":
        prompt_builder = resources["stress_prompt_builder"]
    elif intent == "study_support":
        prompt_builder = resources["support_prompt_builder"]
    elif intent == "request_for_practice":
        print("DEBUG: Tutor Agent is triggering the Practice Flow.")
        insights = insight_agent(conversation_history_str, resources)
        if insights and insights.get("misunderstood_concepts"):
            weakness = insights["misunderstood_concepts"][0]
            return practice_agent(weakness, resources)
        else:
            return practice_agent("c√°c ch·ªß ƒë·ªÅ to√°n l·ªõp 9 t·ªïng qu√°t", resources)
    else: 
        prompt_builder = resources["off_topic_prompt_builder"]
        
    try:
        prompt_text = prompt_builder.run(
            master_prompt=resources["tutor_master_prompt"],
            conversation_history=conversation_history_str
        )["prompt"]
        
        result = resources["generator"].run(prompt_parts=[prompt_text])
        return result["replies"][0]
    except Exception as e:
        print(f"ERROR: Could not generate response for intent '{intent}': {e}")
        return "R·∫•t xin l·ªói, t√¥i ƒëang g·∫∑p m·ªôt ch√∫t s·ª± c·ªë."

def render_chat_message(content: str, is_user: bool, key: str, image: bytes = None):
    """Render tin nh·∫Øn chat, c√≥ th·ªÉ k√®m ·∫£nh."""
    css_class = "user-message" if is_user else "bot-message"
    
    if image:
        st.image(image, width=250)
        
    if content:
        # X·ª≠ l√Ω format text ƒë·ªÉ tr√°nh hi·ªÉn th·ªã r·ªùi r·∫°c
        cleaned_content = content.strip()
        
        # T√°ch th√†nh c√°c paragraph d·ª±a tr√™n line breaks k√©p
        paragraphs = cleaned_content.split('\n\n')
        formatted_paragraphs = []
        
        for paragraph in paragraphs:
            if paragraph.strip():
                # X·ª≠ l√Ω t·ª´ng paragraph
                lines = paragraph.split('\n')
                # Gh√©p c√°c d√≤ng trong c√πng paragraph l·∫°i v·ªõi nhau
                # Ch·ªâ th√™m space n·∫øu d√≤ng kh√¥ng k·∫øt th√∫c b·∫±ng d·∫•u c√¢u
                formatted_lines = []
                for line in lines:
                    line = line.strip()
                    if line:
                        # N·∫øu d√≤ng k·∫øt th√∫c b·∫±ng d·∫•u c√¢u, kh√¥ng th√™m space
                        if line.endswith(('.', ',', ':', ';', '!', '?')):
                            formatted_lines.append(line)
                        else:
                            # N·∫øu kh√¥ng k·∫øt th√∫c b·∫±ng d·∫•u c√¢u, th√™m space ƒë·ªÉ gh√©p v·ªõi d√≤ng ti·∫øp theo
                            formatted_lines.append(line + ' ')
                
                # Gh√©p c√°c d√≤ng trong paragraph
                paragraph_text = ''.join(formatted_lines)
                # X·ª≠ l√Ω kho·∫£ng tr·∫Øng th·ª´a
                paragraph_text = ' '.join(paragraph_text.split())
                formatted_paragraphs.append(paragraph_text)
        
        # Gh√©p c√°c paragraph l·∫°i v·ªõi line break
        final_content = '\n\n'.join(formatted_paragraphs)
        
        # S·ª≠ d·ª•ng markdown ƒë·ªÉ render v·ªõi format ƒë√∫ng
        st.markdown(f'<div class="{css_class}">{final_content}</div>', unsafe_allow_html=True)

def should_trigger_proactive_practice(conversation_history: List[Dict[str, str]]) -> bool:
    """
    Ki·ªÉm tra xem c√≥ n√™n k√≠ch ho·∫°t lu·ªìng luy·ªán t·∫≠p ch·ªß ƒë·ªông kh√¥ng
    b·∫±ng c√°ch ƒë·∫øm s·ªë l∆∞·ª£ng intent 'math_question' ƒë√£ ƒë∆∞·ª£c l∆∞u.
    """
    print("\n--- DEBUG: [should_trigger_proactive_practice] B·∫Øt ƒë·∫ßu ki·ªÉm tra ƒëi·ªÅu ki·ªán ---")

    if len(conversation_history) < 6:
        print("DEBUG: K√≠ch ho·∫°t = False. L√Ω do: L·ªãch s·ª≠ chat qu√° ng·∫Øn.")
        return False
    
    user_intents = [msg['intent'] for msg in conversation_history if msg['role'] == 'user'][-3:]
    
    if len(user_intents) < 3:
        print("DEBUG: K√≠ch ho·∫°t = False. L√Ω do: Kh√¥ng c√≥ ƒë·ªß 3 l∆∞·ª£t t∆∞∆°ng t√°c t·ª´ ng∆∞·ªùi d√πng.")
        return False

    print(f"DEBUG: Ph√¢n t√≠ch 3 intent g·∫ßn nh·∫•t c·ªßa ng∆∞·ªùi d√πng: {user_intents}")
    
    math_question_count = user_intents.count('math_question')
    
    should_trigger = math_question_count >= 2

    print(f"DEBUG: T·ªïng s·ªë intent 'math_question': {math_question_count}/3.")
    print(f"DEBUG: K√≠ch ho·∫°t = {should_trigger}.")
    print("--- K·∫æT TH√öC KI·ªÇM TRA ---")
    
    return should_trigger


def show_typing_indicator():
    """Hi·ªÉn th·ªã indicator khi bot ƒëang suy nghƒ©"""
    return st.markdown('''
        <div class="typing-indicator">
            <span style="margin-right: 10px;">ü§ñ ƒêang suy nghƒ© ...</span>
            <div class="typing-dots">
                <div class="typing-dot"></div>
                <div class="typing-dot"></div>
                <div class="typing-dot"></div>
            </div>
        </div>
    ''', unsafe_allow_html=True)

def handle_modern_auth(supabase: Client):
    """X·ª≠ l√Ω authentication v·ªõi UI hi·ªán ƒë·∫°i"""
    
    # Ki·ªÉm tra session
    try:
        session = supabase.auth.get_session()
        if session and session.user and session.user.email_confirmed_at:
            if "user" not in st.session_state:
                st.session_state.user = session.user
    except:
        if "user" in st.session_state:
            del st.session_state.user
    
    # N·∫øu ch∆∞a ƒëƒÉng nh·∫≠p
    if "user" not in st.session_state or st.session_state.user is None:
        
        # Welcome message
        st.markdown('''
            <div class="welcome-message">
                <h1>ü§ñ Ch√†o m·ª´ng ƒë·∫øn v·ªõi Gia s∆∞ AI</h1>
                <p style="font-size: 1.2em; margin: 1rem 0;">
                    H·ªá th·ªëng gia s∆∞ To√°n th√¥ng minh v·ªõi 5 AI Agent chuy√™n nghi·ªáp
                </p>
                <p style="opacity: 0.9;">
                    ƒêƒÉng nh·∫≠p ƒë·ªÉ b·∫Øt ƒë·∫ßu h√†nh tr√¨nh h·ªçc t·∫≠p c√° nh√¢n h√≥a
                </p>
            </div>
        ''', unsafe_allow_html=True)
        
        # Auth tabs
        tab1, tab2 = st.tabs(["üîë ƒêƒÉng nh·∫≠p", "üìù ƒêƒÉng k√Ω"])
        
        with tab1:
            with st.form("login_form"):
                st.subheader("ƒêƒÉng nh·∫≠p t√†i kho·∫£n")
                email = st.text_input("üìß Email", placeholder="example@email.com")
                password = st.text_input("üîí M·∫≠t kh·∫©u", type="password")
                login_btn = st.form_submit_button("ƒêƒÉng nh·∫≠p", use_container_width=True)
                
                if login_btn:
                    if email and password:
                        try:
                            response = supabase.auth.sign_in_with_password({"email": email, "password": password})
                            if response.user and response.user.email_confirmed_at:
                                st.session_state.user = response.user
                                st.success("‚úÖ ƒêƒÉng nh·∫≠p th√†nh c√¥ng!")
                                time.sleep(1)
                                st.rerun()
                            else:
                                st.warning("‚ö†Ô∏è Vui l√≤ng x√°c th·ª±c email tr∆∞·ªõc khi ƒëƒÉng nh·∫≠p!")
                        except Exception as e:
                            if "invalid login credentials" in str(e).lower():
                                st.error("‚ùå Email ho·∫∑c m·∫≠t kh·∫©u kh√¥ng ƒë√∫ng")
                            else:
                                st.error(f"‚ùå L·ªói ƒëƒÉng nh·∫≠p: {str(e)}")
                    else:
                        st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p ƒë·∫ßy ƒë·ªß th√¥ng tin")
        
        with tab2:
            with st.form("register_form"):
                st.subheader("T·∫°o t√†i kho·∫£n m·ªõi")
                display_name = st.text_input("üë§ T√™n c·ªßa b·∫°n", placeholder="Nguy·ªÖn VƒÉn A")
                new_email = st.text_input("üìß Email", placeholder="example@email.com")
                new_password = st.text_input("üîí M·∫≠t kh·∫©u", type="password")
                register_btn = st.form_submit_button("ƒêƒÉng k√Ω", use_container_width=True)
                
                if register_btn:
                    if display_name and new_email and new_password:
                        try:
                            # --- THAY ƒê·ªîI 3: G·ª¨I K√àM T√äN TRONG OPTIONS ---
                            response = supabase.auth.sign_up({
                                "email": new_email, 
                                "password": new_password,
                                "options": {
                                    "data": {
                                        "display_name": display_name
                                    }
                                }
                            })
                            if response.user:
                                st.success("üéâ ƒêƒÉng k√Ω th√†nh c√¥ng!")
                                st.info("üìß Vui l√≤ng ki·ªÉm tra email ƒë·ªÉ x√°c th·ª±c t√†i kho·∫£n")
                        except Exception as e:
                            if "already registered" in str(e).lower():
                                st.error("‚ùå Email ƒë√£ ƒë∆∞·ª£c ƒëƒÉng k√Ω")
                            else:
                                st.error(f"‚ùå L·ªói ƒëƒÉng k√Ω: {str(e)}")
                    else:
                        st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p ƒë·∫ßy ƒë·ªß T√™n, Email v√† M·∫≠t kh·∫©u")
        
        # Feature showcase
        st.subheader("üöÄ T√≠nh nƒÉng n·ªïi b·∫≠t")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown('''
                <div class="feature-card">
                    <h3>üß† 5 AI Agent th√¥ng minh</h3>
                    <p>H·ªá th·ªëng ƒëa t√°c nh√¢n chuy√™n nghi·ªáp cho tr·∫£i nghi·ªám h·ªçc t·∫≠p t·ªëi ∆∞u</p>
                </div>
            ''', unsafe_allow_html=True)
            
            st.markdown('''
                <div class="feature-card">
                    <h3>üìö D·ª±a tr√™n SGK ch√≠nh th·ª©c</h3>
                    <p>N·ªôi dung chu·∫©n theo ch∆∞∆°ng tr√¨nh To√°n l·ªõp 9</p>
                </div>
            ''', unsafe_allow_html=True)
        
        with col2:
            st.markdown('''
                <div class="feature-card">
                    <h3>üéØ H·ªçc t·∫≠p c√° nh√¢n h√≥a</h3>
                    <p>Ph√¢n t√≠ch ƒëi·ªÉm y·∫øu v√† ƒë·ªÅ xu·∫•t b√†i t·∫≠p ph√π h·ª£p</p>
                </div>
            ''', unsafe_allow_html=True)
            
            st.markdown('''
                <div class="feature-card">
                    <h3>üé• Video b√†i gi·∫£ng</h3>
                    <p>Kho video phong ph√∫ v·ªõi l·ªùi gi·∫£i chi ti·∫øt</p>
                </div>
            ''', unsafe_allow_html=True)
        
        return False
    
    return True

def main():
    """H√†m ch√≠nh c·ªßa ·ª©ng d·ª•ng"""
    
    # Kh·ªüi t·∫°o Supabase
    supabase = init_supabase_client()
    
    if not handle_modern_auth(supabase):
        return
    
    # N·∫øu ƒë√£ ƒëƒÉng nh·∫≠p, l·∫•y th√¥ng tin user
    user = st.session_state.user
    user_id = user.id

    display_name = user.user_metadata.get("display_name", user.email)
    
    with st.spinner("üöÄ ƒêang kh·ªüi t·∫°o h·ªá th·ªëng AI..."):
        resources = load_resources()
    
    # --- Giao di·ªán ch√≠nh sau khi ƒëƒÉng nh·∫≠p ---
    
    # Header
    st.markdown(f'''
        <div style="text-align: center; padding: 1rem; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 15px; margin-bottom: 1rem; color: white; box-shadow: 0 8px 32px rgba(0,0,0,0.1);">
            <h1>ü§ñ Gia s∆∞ To√°n AI</h1>
            <p class="status-online">‚óè Online - S·∫µn s√†ng h·ªó tr·ª£ {display_name}</p>
        </div>
    ''', unsafe_allow_html=True)
    
    # Kh·ªüi t·∫°o session state cho cu·ªôc tr√≤ chuy·ªán
    if "messages" not in st.session_state:
        st.session_state.messages = []
        # Th√™m tin nh·∫Øn ch√†o m·ª´ng ƒë·∫ßu ti√™n
        welcome_msg = "Xin ch√†o! T√¥i l√† gia s∆∞ AI c·ªßa b·∫°n üòä. H√¥m nay ch√∫ng ta c√πng h·ªçc To√°n nh√©!"
        st.session_state.messages.append({"role": "assistant", "content": welcome_msg, "intent": "greeting_social"})

    # Kh·ªüi t·∫°o session state ƒë·ªÉ theo d√µi audio ƒë√£ x·ª≠ l√Ω
    if "processed_audio_ids" not in st.session_state:
        st.session_state.processed_audio_ids = set()

    # Container ƒë·ªÉ ch·ª©a c√°c tin nh·∫Øn chat
    chat_placeholder = st.container()
    with chat_placeholder:
        for i, msg_data in enumerate(st.session_state.messages):
            is_user = msg_data["role"] == "user"
            # S·ª≠ d·ª•ng h√†m render t√πy ch·ªânh
            render_chat_message(msg_data["content"], is_user, key=f"msg_{i}")

    # Audio input section with better error handling
    st.markdown("#### Ho·∫∑c ghi √¢m gi·ªçng n√≥i:")
    
    # Check if running in secure context for microphone access
    audio_input = None
    try:
        # Use Streamlit's built-in audio_input which is more stable
        audio_input = st.audio_input("üé§ Nh·∫•n ƒë·ªÉ ghi √¢m", help="Ghi √¢m c√¢u h·ªèi c·ªßa b·∫°n b·∫±ng ti·∫øng Vi·ªát")
    except Exception as e:
        st.warning("‚ö†Ô∏è Kh√¥ng th·ªÉ truy c·∫≠p microphone. Vui l√≤ng s·ª≠ d·ª•ng form nh·∫≠p text b√™n d∆∞·ªõi.")
        print(f"DEBUG: Audio input error: {e}")

    # 2. Form Nh·∫≠p li·ªáu cho Text v√† ·∫¢nh
    with st.form(key="chat_form", clear_on_submit=True):
        # Chia layout
        col1, col2 = st.columns([1, 4])
        with col1:
            uploaded_image = st.file_uploader("ƒê√≠nh k√®m ·∫£nh", type=["png", "jpg", "jpeg"], label_visibility="collapsed")
        with col2:
            user_text = st.text_input("Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n...", placeholder="Nh·∫≠p c√¢u h·ªèi ho·∫∑c m√¥ t·∫£ cho ·∫£nh...", label_visibility="collapsed")
        
        submit_button = st.form_submit_button(label="G·ª≠i")

    final_user_text = ""
    final_image_data = None

    # Handle audio input if available - v·ªõi logic tr√°nh x·ª≠ l√Ω l·∫∑p l·∫°i
    if audio_input is not None:
        # T·∫°o unique ID cho audio file d·ª±a tr√™n file_id v√† size
        audio_id = f"{audio_input.file_id}_{audio_input.size}" if hasattr(audio_input, 'file_id') and hasattr(audio_input, 'size') else f"{id(audio_input)}_{len(audio_input.getvalue())}"
        
        # Ch·ªâ x·ª≠ l√Ω n·∫øu audio n√†y ch∆∞a ƒë∆∞·ª£c x·ª≠ l√Ω
        if audio_id not in st.session_state.processed_audio_ids:
            with st.spinner("üéß ƒêang x·ª≠ l√Ω gi·ªçng n√≥i..."):
                transcribed_text = transcribe_audio(audio_input, resources["whisper_model"])
                if transcribed_text and transcribed_text.strip() and len(transcribed_text.strip()) > 1:
                    final_user_text = transcribed_text
                    st.success(f"‚úÖ ƒê√£ nh·∫≠n di·ªán: {transcribed_text}")
                    # ƒê√°nh d·∫•u audio n√†y ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω
                    st.session_state.processed_audio_ids.add(audio_id)
                else:
                    st.warning("‚ö†Ô∏è Kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c n·ªôi dung. Vui l√≤ng th·ª≠ l·∫°i ho·∫∑c s·ª≠ d·ª•ng text input.")
                    # V·∫´n ƒë√°nh d·∫•u ƒë·ªÉ tr√°nh x·ª≠ l√Ω l·∫°i
                    st.session_state.processed_audio_ids.add(audio_id)
        else:
            # Audio ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω, kh√¥ng l√†m g√¨ c·∫£
            print(f"DEBUG: Audio {audio_id} ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω tr∆∞·ªõc ƒë√≥, b·ªè qua.")
    
    # Handle form submission
    elif submit_button:
        final_user_text = user_text
        if uploaded_image:
            final_image_data = uploaded_image.getvalue()

    if final_user_text or final_image_data:
        
        st.session_state.messages.append({
            "role": "user", 
            "content": final_user_text, 
            "image": final_image_data,
            "intent": "unknown"
        })
        with chat_placeholder:
             render_chat_message(final_user_text, is_user=True, image=final_image_data, key=f"user_{len(st.session_state.messages)}")

        history_str_for_llm = "\n".join([f"{msg['role'].capitalize()}: {msg['content']}" for msg in st.session_state.messages[-10:] if msg['content']])
        detected_intent = classify_intent(history_str_for_llm, resources)
        st.session_state.messages[-1]["intent"] = detected_intent
        
        with chat_placeholder:
            typing_indicator_placeholder = show_typing_indicator()

        if final_image_data or detected_intent == "math_question":
            bot_response = problem_solving_engine(
                query_text=final_user_text,
                query_image=final_image_data,
                conversation_history_str=history_str_for_llm,
                resources=resources
            )
        else:
            bot_response = tutor_agent_response(
                user_input=final_user_text, 
                intent=detected_intent,
                conversation_history_str=history_str_for_llm,
                resources=resources,
                supabase=supabase,
                user_id=user_id,
                display_name=display_name
            )
        
        typing_indicator_placeholder.empty()

        st.session_state.messages.append({"role": "assistant", "content": bot_response, "intent": detected_intent, "image": None})
        with chat_placeholder:
            render_chat_message(bot_response, is_user=False, key=f"bot_{len(st.session_state.messages)}")

        if should_trigger_proactive_practice(st.session_state.messages):
    
            with chat_placeholder:
                proactive_typing_placeholder = show_typing_indicator()
            
            try:
                print("\n--- DEBUG: [Proactive Flow] B·∫Øt ƒë·∫ßu lu·ªìng ph√¢n t√≠ch v√† ƒë·ªÅ xu·∫•t ---")
                
                history_str_for_insight = "\n".join([f"{msg['role'].capitalize()}: {msg['content']}" for msg in st.session_state.messages[-10:]])
                
                # G·ªçi Insight Agent
                print("DEBUG: [Proactive Flow] G·ªçi Insight Agent...")
                insights = insight_agent(history_str_for_insight, resources)
                print(f"DEBUG: [Proactive Flow] Insight Agent tr·∫£ v·ªÅ: {insights}")
                
                if insights and isinstance(insights, dict) and insights.get("misunderstood_concepts"):
                    
                    current_profile = get_user_profile(supabase, user_id)
                    
                    old_concepts = current_profile.get("misunderstood_concepts", []) if current_profile else []
                    
                    new_concepts = insights["misunderstood_concepts"]
                 
                    combined_concepts_set = set(old_concepts) | set(new_concepts)
                    updated_concepts = list(combined_concepts_set)
                    
                    last_weakness = new_concepts[0] if new_concepts else (old_concepts[0] if old_concepts else None)
                    user_email = user.email
                    
                    profile_data_to_save = {
                        "email": user_email, 
                        "misunderstood_concepts": updated_concepts, 
                        "last_weakness": last_weakness,
                        "updated_at": datetime.now().isoformat()
                    }
                    
                    print(f"DEBUG: [Proactive Flow] D·ªØ li·ªáu c·∫≠p nh·∫≠t (ƒë√£ c·ªông d·ªìn): {profile_data_to_save}")
                    update_user_profile(supabase, user_id, profile_data_to_save)
                    
                    st.toast("‚úÖ ƒê√£ ph√¢n t√≠ch v√† c·∫≠p nh·∫≠t h·ªì s∆° h·ªçc t·∫≠p!", icon="üß†")
                    print(f"DEBUG: [Proactive Flow] Ph√°t hi·ªán ƒëi·ªÉm y·∫øu: '{last_weakness}'. G·ªçi Practice Agent...")
                    
                    practice_response = practice_agent(last_weakness, resources)
                    
                    proactive_msg = f"üí° **Ph√¢n t√≠ch nhanh:** D·ª±a tr√™n c√°c c√¢u h·ªèi v·ª´a r·ªìi, t√¥i nh·∫≠n th·∫•y b·∫°n c√≥ th·ªÉ c·∫ßn luy·ªán t·∫≠p th√™m v·ªÅ ch·ªß ƒë·ªÅ **'{last_weakness}'**. ƒê√¢y l√† m·ªôt s·ªë g·ª£i √Ω cho b·∫°n:\n\n{practice_response}"
                    
                    proactive_typing_placeholder.empty()
                    st.session_state.messages.append({"role": "assistant", "content": proactive_msg, "intent": "proactive_suggestion"})
                    
                    with chat_placeholder:
                        render_chat_message(proactive_msg, is_user=False, key=f"proactive_{len(st.session_state.messages)}")
                
                else:
                    print("DEBUG: [Proactive Flow] Insight Agent kh√¥ng t√¨m th·∫•y ƒëi·ªÉm y·∫øu n√†o c·ª• th·ªÉ. B·ªè qua ƒë·ªÅ xu·∫•t.")
                    proactive_typing_placeholder.empty()

            except Exception as e:
                print(f"ERROR: [Proactive Flow] ƒê√£ x·∫£y ra l·ªói: {str(e)}")
                proactive_typing_placeholder.empty()

        # Rerun ƒë·ªÉ c·∫≠p nh·∫≠t giao di·ªán
        st.rerun()

    # Sidebar v·ªõi th√¥ng tin khi ƒë√£ ƒëƒÉng nh·∫≠p
    with st.sidebar:
        st.header(f"üë§ Ch√†o, {display_name}")
        st.caption(f"Email: {user.email}")
        
        if st.button("ƒêƒÉng xu·∫•t", use_container_width=True):
            supabase.auth.sign_out()
            # X√≥a c√°c session state li√™n quan ƒë·∫øn user
            keys_to_delete = ["user", "messages", "processed_audio_ids"]
            for key in keys_to_delete:
                if key in st.session_state:
                    del st.session_state[key]
            st.success("‚úÖ ƒê√£ ƒëƒÉng xu·∫•t!")
            time.sleep(1)
            st.rerun()
        
        if st.button("üóëÔ∏è X√≥a l·ªãch s·ª≠ chat", use_container_width=True):
            st.session_state.messages = []
            # C≈©ng x√≥a audio ƒë√£ x·ª≠ l√Ω ƒë·ªÉ c√≥ th·ªÉ ghi √¢m l·∫°i
            st.session_state.processed_audio_ids = set()
            st.rerun()

if __name__ == "__main__":
    main()