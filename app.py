from altair import Bin
from numpy import tri
import streamlit as st
import pickle
import json
import os
import random
import time
import re
import hashlib
from typing import List, Dict, Any
from streamlit_chat import message
from dotenv import load_dotenv
from datetime import datetime
from supabase_utils import init_supabase_client, update_user_profile, get_user_profile
from supabase import Client
from sympy import Rem
from PIL import Image
import io
from faster_whisper import WhisperModel
import tempfile

load_dotenv()

# Haystack imports
from haystack import Pipeline, Document
from haystack.document_stores.in_memory import InMemoryDocumentStore
from haystack.components.retrievers.in_memory import InMemoryBM25Retriever, InMemoryEmbeddingRetriever
from haystack.components.builders import PromptBuilder
from haystack.components.embedders import SentenceTransformersDocumentEmbedder, SentenceTransformersTextEmbedder

# Google AI integration - Custom Component
import google.generativeai as genai
from haystack import component, default_from_dict, default_to_dict

@component
class CustomGoogleAIGenerator:
    """
    Má»™t component Haystack tÃ¹y chá»‰nh Ä‘á»ƒ gá»i trá»±c tiáº¿p API Gemini cá»§a Google.
    """
    def __init__(self, api_key: str, model_name: str = "gemini-1.5-pro"):
        self.api_key = api_key
        self.model_name = model_name
        genai.configure(api_key=self.api_key)
        
        self.safety_settings = [
            {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
        ]

        self.generation_config = genai.types.GenerationConfig(
            temperature=0.2,
            max_output_tokens=1024 
        )

        self.model = genai.GenerativeModel(
            self.model_name,
            generation_config=self.generation_config,
            safety_settings=self.safety_settings 
        )


    def to_dict(self):
        return default_to_dict(self, api_key=self.api_key, model_name=self.model_name)

    @classmethod
    def from_dict(cls, data):
        return default_from_dict(cls, data)

    @component.output_types(replies=List[str])
    def run(self, prompt_parts: List[Any]): 
        """
        Gá»­i má»™t prompt Ä‘a phÆ°Æ¡ng thá»©c (vÄƒn báº£n vÃ  hÃ¬nh áº£nh) Ä‘áº¿n API Gemini.
        """
        try:
            processed_parts = []
            for part in prompt_parts:
                if isinstance(part, bytes): 
                    try:
                        img = Image.open(io.BytesIO(part))
                        processed_parts.append(img)
                    except Exception as e:
                        print(f"Lá»—i khi xá»­ lÃ½ áº£nh: {e}")
                else:
                    processed_parts.append(part) 

            response = self.model.generate_content(processed_parts)
            return {"replies": [response.text]}
        except Exception as e:
            return {"replies": [f"Xin lá»—i, Ä‘Ã£ cÃ³ lá»—i xáº£y ra khi káº¿t ná»‘i vá»›i mÃ´ hÃ¬nh AI."]}

st.set_page_config(
    page_title="AI Math Tutor",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded",
    menu_items={
        'About': "Gia sÆ° ToÃ¡n AI thÃ´ng minh cho há»c sinh lá»›p 9"
    }
)

st.markdown("""
<style>
    /* Hide Streamlit branding */
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    header {visibility: hidden;}
    
    /* Main app styling */
    .main {
        padding: 1rem;
    }
    
    /* Chat container */
    .chat-container {
        max-height: 600px;
        overflow-y: auto;
        padding: 1rem;
        border-radius: 15px;
        background: linear-gradient(135deg, #2c5f7c 0%, #546e7a 100%);
        margin-bottom: 1rem;
        box-shadow: 0 8px 32px rgba(0,0,0,0.1);
    }
    
    /* User message */
    .user-message {
        background: linear-gradient(135deg, #1976d2 0%, #42a5f5 100%);
        color: white;
        padding: 12px 16px;
        border-radius: 18px 18px 4px 18px;
        margin: 8px 0;
        margin-left: 20%;
        box-shadow: 0 4px 12px rgba(25, 118, 210, 0.3);
        animation: slideInRight 0.3s ease-out;
    }
    
    /* Bot message */
    .bot-message {
        background: linear-gradient(135deg, #607d8b 0%, #78909c 100%);
        color: white;
        padding: 12px 16px;
        border-radius: 18px 18px 18px 4px;
        margin: 8px 0;
        margin-right: 20%;
        box-shadow: 0 4px 12px rgba(96, 125, 139, 0.3);
        animation: slideInLeft 0.3s ease-out;
    }
    
    /* Animations */
    @keyframes slideInRight {
        from { transform: translateX(100%); opacity: 0; }
        to { transform: translateX(0); opacity: 1; }
    }
    
    @keyframes slideInLeft {
        from { transform: translateX(-100%); opacity: 0; }
        to { transform: translateX(0); opacity: 1; }
    }
    
    @keyframes pulse {
        0%, 100% { transform: scale(1); }
        50% { transform: scale(1.05); }
    }
    
    /* Typing indicator */
    .typing-indicator {
        display: flex;
        align-items: center;
        padding: 12px 16px;
        background: rgba(255,255,255,0.1);
        border-radius: 18px;
        margin: 8px 0;
        margin-right: 20%;
        animation: pulse 2s infinite;
    }
    
    .typing-dots {
        display: flex;
        gap: 4px;
    }
    
    .typing-dot {
        width: 8px;
        height: 8px;
        border-radius: 50%;
        background: white;
        animation: typingDots 1.5s infinite;
    }
    
    .typing-dot:nth-child(2) { animation-delay: 0.3s; }
    .typing-dot:nth-child(3) { animation-delay: 0.6s; }
    
    @keyframes typingDots {
        0%, 60%, 100% { opacity: 0.3; }
        30% { opacity: 1; }
    }
    
    /* Sidebar styling */
    .sidebar .sidebar-content {
        background: linear-gradient(135deg, #2c5f7c 0%, #546e7a 100%);
        border-radius: 15px;
        padding: 1rem;
        margin: 1rem 0;
    }
    
    /* Input styling - Fix pink outline issue */
    .stTextInput > div > div > input {
        border-radius: 25px !important;
        border: 2px solid #1976d2 !important;
        padding: 12px 20px;
        font-size: 16px;
        transition: all 0.3s ease;
        outline: none !important;
        box-shadow: none !important;
    }
    
    .stTextInput > div > div > input:focus {
        border-color: #42a5f5 !important;
        box-shadow: 0 0 20px rgba(66, 165, 245, 0.3) !important;
        outline: none !important;
    }
    
    /* Remove default Streamlit input container styling */
    .stTextInput > div {
        border: none !important;
        background: transparent !important;
    }
    
    .stTextInput {
        background: transparent !important;
    }
    
    /* Button styling */
    .stButton > button {
        border-radius: 25px;
        border: none;
        background: linear-gradient(135deg, #1976d2 0%, #42a5f5 100%);
        color: white;
        padding: 12px 24px;
        font-weight: 600;
        transition: all 0.3s ease;
        box-shadow: 0 4px 12px rgba(25, 118, 210, 0.3);
    }
    
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 6px 16px rgba(25, 118, 210, 0.4);
    }
    
    /* Welcome message */
    .welcome-message {
        text-align: center;
        padding: 2rem;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        border-radius: 20px;
        color: white;
        margin: 2rem 0;
        box-shadow: 0 8px 32px rgba(0,0,0,0.1);
    }
    
    /* Feature cards */
    .feature-card {
        background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
        border-radius: 15px;
        padding: 1.5rem;
        margin: 1rem 0;
        color: white;
        box-shadow: 0 4px 12px rgba(240, 147, 251, 0.3);
        transition: transform 0.3s ease;
    }
    
    .feature-card:hover {
        transform: translateY(-5px);
    }
    
    /* Status indicators */
    .status-online {
        color: #4ade80;
        font-weight: 600;
    }
    
    .status-thinking {
        color: #fbbf24;
        font-weight: 600;
    }
    
    /* Math expression styling */
    .math-expression {
        background: rgba(255,255,255,0.1);
        padding: 8px 12px;
        border-radius: 8px;
        font-family: 'Courier New', monospace;
        margin: 4px 0;
    }
</style>
""", unsafe_allow_html=True)

# Kiá»ƒm tra API key
if "GOOGLE_API_KEY" not in os.environ:
    st.error("âš ï¸ KhÃ´ng tÃ¬m tháº¥y API key. Vui lÃ²ng cáº¥u hÃ¬nh biáº¿n mÃ´i trÆ°á»ng.")
    st.stop()

@st.cache_resource
def load_resources():
    """Load vÃ  khá»Ÿi táº¡o táº¥t cáº£ tÃ i nguyÃªn cá»§a há»‡ thá»‘ng"""
    
    # Load documents
    try:
        with open("embedded_documents.pkl", "rb") as f:
            documents = pickle.load(f)
    except FileNotFoundError:
        st.error("âŒ KhÃ´ng tÃ¬m tháº¥y dá»¯ liá»‡u há»c liá»‡u")
        st.stop()
    
    # Load videos
    try:
        with open("videos.json", "r", encoding="utf-8") as f:
            videos_data = json.load(f)
    except FileNotFoundError:
        st.error("âŒ KhÃ´ng tÃ¬m tháº¥y dá»¯ liá»‡u video")
        st.stop()
    
    # Initialize document store
    document_store = InMemoryDocumentStore()
    document_store.write_documents(documents)
    
    # Initialize components
    retriever = InMemoryEmbeddingRetriever(document_store=document_store)
    text_embedder = SentenceTransformersTextEmbedder(
        model="bkai-foundation-models/vietnamese-bi-encoder"
    )

    print("DEBUG: Loading Faster Whisper model...")
    model_size = "small" 

    # Cháº¡y trÃªn CPU vá»›i INT8 Ä‘á»ƒ tá»‘i Æ°u
    whisper_model = WhisperModel(model_size, device="cpu", compute_type="int8")

    print(f"DEBUG: Faster Whisper model '{model_size}' loaded successfully.")
    
    # Templates
    informer_template = """
        Báº¡n lÃ  má»™t Gia sÆ° ToÃ¡n AI chuyÃªn nghiá»‡p. Vai trÃ² cá»§a báº¡n lÃ  cung cáº¥p má»™t lá»i giáº£i hoáº·c má»™t lá»i giáº£i thÃ­ch chi tiáº¿t, chÃ­nh xÃ¡c vÃ  dá»… hiá»ƒu cho há»c sinh lá»›p 9.

        **QUY TRÃŒNH Cá»¦A Báº N:**
        1.  **Äá»c Lá»‹ch sá»­ TrÃ² chuyá»‡n:** Hiá»ƒu rÃµ bá»‘i cáº£nh vÃ  cÃ¢u há»i trÆ°á»›c Ä‘Ã³ cá»§a há»c sinh.
        2.  **NghiÃªn cá»©u TÃ i liá»‡u:** Tham kháº£o ká»¹ cÃ¡c thÃ´ng tin tá»« sÃ¡ch giÃ¡o khoa Ä‘Æ°á»£c cung cáº¥p.
        3.  **Tráº£ lá»i cÃ¢u há»i cuá»‘i cÃ¹ng:** Dá»±a vÃ o cáº£ lá»‹ch sá»­ vÃ  tÃ i liá»‡u, hÃ£y tráº£ lá»i cÃ¢u há»i cuá»‘i cÃ¹ng cá»§a há»c sinh.

        **YÃŠU Cáº¦U TRÃŒNH BÃ€Y:**
        -   Sá»­ dá»¥ng ngÃ´n ngá»¯ sÆ° pháº¡m, rÃµ rÃ ng, tá»«ng bÆ°á»›c má»™t.
        -   Sá»­ dá»¥ng Markdown Ä‘á»ƒ Ä‘á»‹nh dáº¡ng cÃ¡c cÃ´ng thá»©c toÃ¡n há»c, cÃ¡c Ä‘á» má»¥c vÃ  nháº¥n máº¡nh cÃ¡c Ä‘iá»ƒm quan trá»ng.
        -   LuÃ´n tráº£ lá»i báº±ng tiáº¿ng Viá»‡t.

        ---
        **Lá»ŠCH Sá»¬ TRÃ’ CHUYá»†N Gáº¦N ÄÃ‚Y:**
        {{ conversation_history }}
        ---
        **THÃ”NG TIN SÃCH GIÃO KHOA (Tá»ª RAG):**
        {% for doc in documents %}
        {{ doc.content }}
        {% endfor %}
        ---

        **CÃ¢u há»i cuá»‘i cÃ¹ng cá»§a há»c sinh:** {{ query }}

        **Lá»i giáº£i chi tiáº¿t cá»§a báº¡n:**
        """

    practice_template = """
        Báº¡n lÃ  má»™t chuyÃªn gia ra Ä‘á» thi vÃ  tÆ° váº¥n há»c liá»‡u mÃ´n ToÃ¡n.

        **NHIá»†M Vá»¤:**
        Dá»±a trÃªn **chá»§ Ä‘á» yáº¿u** cá»§a há»c sinh vÃ  **danh sÃ¡ch video** Ä‘Æ°á»£c cung cáº¥p, hÃ£y thá»±c hiá»‡n 2 viá»‡c:

        1.  **Táº¡o 2 BÃ i táº­p Má»›i:**
            -   CÃ¡c bÃ i táº­p pháº£i liÃªn quan trá»±c tiáº¿p Ä‘áº¿n chá»§ Ä‘á» yáº¿u.
            -   Äá»™ khÃ³ tÆ°Æ¡ng Ä‘Æ°Æ¡ng chÆ°Æ¡ng trÃ¬nh lá»›p 9.
            -   BÃ i táº­p pháº£i hoÃ n toÃ n má»›i, khÃ´ng Ä‘Æ°á»£c trÃ¹ng láº·p vá»›i cÃ¡c vÃ­ dá»¥ phá»• biáº¿n.
        2.  **Äá» xuáº¥t 1 Video PhÃ¹ há»£p nháº¥t:**
            -   Chá»n ra Má»˜T video tá»« danh sÃ¡ch cÃ³ ná»™i dung liÃªn quan cháº·t cháº½ nháº¥t Ä‘áº¿n chá»§ Ä‘á» yáº¿u.

        **THÃ”NG TIN Äáº¦U VÃ€O:**
        -   **Chá»§ Ä‘á» yáº¿u cá»§a há»c sinh:** '{{ student_weakness }}'
        -   **Danh sÃ¡ch video cÃ³ sáºµn (JSON):** {{ video_cheatsheet_json }}

        **YÃŠU Cáº¦U OUTPUT:**
        Chá»‰ tráº£ lá»i theo Ä‘á»‹nh dáº¡ng Markdown dÆ°á»›i Ä‘Ã¢y, khÃ´ng thÃªm báº¥t ká»³ lá»i dáº«n hay giáº£i thÃ­ch nÃ o khÃ¡c.

        ### ğŸ¯ BÃ€I Táº¬P Cá»¦NG Cá»
        1.  **BÃ i 1:** [Ná»™i dung cÃ¢u há»i bÃ i táº­p 1]
        2.  **BÃ i 2:** [Ná»™i dung cÃ¢u há»i bÃ i táº­p 2]


        ### ğŸ“¹ VIDEO Äá»€ XUáº¤T
        **[TÃªn video]**
        ğŸ¬ Link: https://www.youtube.com/playlist?list=PL5q2T2FxzK7XY4s9FqDi6KCFEpGr2LX2D"""

    insight_template = """
        Báº¡n lÃ  má»™t chuyÃªn gia phÃ¢n tÃ­ch giÃ¡o dá»¥c. Nhiá»‡m vá»¥ cá»§a báº¡n lÃ  Ä‘á»c ká»¹ Ä‘oáº¡n há»™i thoáº¡i vÃ  xÃ¡c Ä‘á»‹nh chÃ­nh xÃ¡c nhá»¯ng khÃ¡i niá»‡m toÃ¡n há»c mÃ  há»c sinh Ä‘ang hiá»ƒu sai.

        **HÆ¯á»šNG DáºªN:**
        - Äá»c ká»¹ toÃ n bá»™ há»™i thoáº¡i.
        - Táº­p trung vÃ o nhá»¯ng cÃ¢u há»i hoáº·c nháº­n Ä‘á»‹nh cá»§a 'User' thá»ƒ hiá»‡n sá»± nháº§m láº«n hoáº·c thiáº¿u kiáº¿n thá»©c.
        - Dá»±a trÃªn sá»± nháº§m láº«n Ä‘Ã³, xÃ¡c Ä‘á»‹nh khÃ¡i niá»‡m toÃ¡n há»c cá»‘t lÃµi bá»‹ hiá»ƒu sai.
        - Chá»‰ tráº£ lá»i báº±ng má»™t Ä‘á»‘i tÆ°á»£ng JSON duy nháº¥t theo Ä‘á»‹nh dáº¡ng sau. KhÃ´ng thÃªm báº¥t ká»³ giáº£i thÃ­ch hay vÄƒn báº£n nÃ o khÃ¡c.

        **VÃ Dá»¤:**
        ---
        Há»™i thoáº¡i:
        User: há»‡ thá»©c Vi-Ã©t dÃ¹ng Ä‘á»ƒ lÃ m gÃ¬?
        Assistant: ...
        User: váº­y náº¿u phÆ°Æ¡ng trÃ¬nh vÃ´ nghiá»‡m thÃ¬ váº«n tÃ­nh tá»•ng vÃ  tÃ­ch cÃ¡c nghiá»‡m Ä‘Æ°á»£c Ä‘Ãºng khÃ´ng?
        ---
        JSON Output:
        {"misunderstood_concepts": ["Ä‘iá»u kiá»‡n Ã¡p dá»¥ng há»‡ thá»©c Vi-Ã©t"], "sentiment": "confused"}
        ---

        **BÃ‚Y GIá»œ, HÃƒY PHÃ‚N TÃCH Há»˜I THOáº I SAU:**

        **Há»™i thoáº¡i:**
        {{ conversation_history }}

        **JSON Output:**
        """

    verifier_template = """Bin lÃ  má»™t ngÆ°á»i kiá»ƒm Ä‘á»‹nh cháº¥t lÆ°á»£ng toÃ¡n há»c cá»±c ká»³ khÃ³ tÃ­nh vÃ  chÃ­nh xÃ¡c.
        Nhiá»‡m vá»¥ cá»§a báº¡n lÃ  kiá»ƒm tra xem lá»i giáº£i Ä‘Æ°á»£c Ä‘á» xuáº¥t cÃ³ hoÃ n toÃ n Ä‘Ãºng vá» máº·t toÃ¡n há»c vÃ  logic hay khÃ´ng.

        **CÃ¢u há»i cá»§a há»c sinh:** {{ query }}

        **Lá»i giáº£i Ä‘Æ°á»£c Ä‘á» xuáº¥t:** {{ informer_answer }}

        **YÃŠU Cáº¦U:**
        HÃ£y kiá»ƒm tra tá»«ng bÆ°á»›c, tá»«ng cÃ´ng thá»©c vÃ  káº¿t quáº£ cuá»‘i cÃ¹ng. Sau Ä‘Ã³, chá»‰ tráº£ lá»i báº±ng má»™t Ä‘á»‘i tÆ°á»£ng JSON duy nháº¥t theo Ä‘á»‹nh dáº¡ng sau.

        **JSON Output:**
        {"is_correct": [true hoáº·c false], "correction_suggestion": "[Náº¿u sai, hÃ£y giáº£i thÃ­ch ngáº¯n gá»n vÃ  chÃ­nh xÃ¡c lá»—i sai náº±m á»Ÿ Ä‘Ã¢u. Náº¿u Ä‘Ãºng, Ä‘á»ƒ trá»‘ng chuá»—i nÃ y.]"}
        """

    intent_template = """
        Báº¡n lÃ  má»™t há»‡ thá»‘ng phÃ¢n loáº¡i Ã½ Ä‘á»‹nh cá»±c ká»³ chÃ­nh xÃ¡c. Dá»±a vÃ o cÃ¢u há»i cuá»‘i cÃ¹ng cá»§a ngÆ°á»i dÃ¹ng, hÃ£y phÃ¢n loáº¡i nÃ³ vÃ o Má»˜T trong cÃ¡c loáº¡i sau.

        **Äá»ŠNH NGHÄ¨A CÃC LOáº I:**
        - 'greeting_social': ChÃ o há»i, xÃ£ giao, cáº£m Æ¡n, táº¡m biá»‡t.
        - 'math_question': Báº¥t ká»³ cÃ¢u há»i nÃ o liÃªn quan trá»±c tiáº¿p Ä‘áº¿n kiáº¿n thá»©c toÃ¡n há»c, bao gá»“m giáº£i bÃ i táº­p, tÃ­nh toÃ¡n, há»i Ä‘á»‹nh nghÄ©a, há»i cÃ´ng thá»©c, há»i tÃ­nh cháº¥t.
        - 'request_for_practice': YÃªu cáº§u bÃ i táº­p luyá»‡n táº­p, muá»‘n thá»±c hÃ nh.
        - 'expression_of_stress': Biá»ƒu hiá»‡n cÄƒng tháº³ng, má»‡t má»i, náº£n lÃ²ng.
        - 'study_support': Há»i vá» phÆ°Æ¡ng phÃ¡p há»c chung, cÃ¡ch Ä‘á»ƒ tiáº¿n bá»™, tÃ¬m kiáº¿m Ä‘á»™ng lá»±c.
        - 'off_topic': Chá»§ Ä‘á» hoÃ n toÃ n khÃ´ng liÃªn quan Ä‘áº¿n há»c táº­p.

        **VÃ Dá»¤:**
        ---
        User: ChÃ o báº¡n
        PhÃ¢n loáº¡i: greeting_social
        ---
        User: Giáº£i giÃºp mÃ¬nh phÆ°Æ¡ng trÃ¬nh x^2 + 5x - 6 = 0
        PhÃ¢n loáº¡i: math_question
        ---
        User: há»‡ thá»©c Vi-Ã©t dÃ¹ng Ä‘á»ƒ lÃ m gÃ¬?  <-- VÃ Dá»¤ Má»šI QUAN TRá»ŒNG
        PhÃ¢n loáº¡i: math_question
        ---
        User: BÃ i nÃ y khÃ³ quÃ¡, mÃ¬nh náº£n tháº­t
        PhÃ¢n loáº¡i: expression_of_stress
        ---
        User: CÃ³ bÃ i nÃ o tÆ°Æ¡ng tá»± Ä‘á»ƒ mÃ¬nh luyá»‡n táº­p thÃªm khÃ´ng?
        PhÃ¢n loáº¡i: request_for_practice
        ---
        User: LÃ m sao Ä‘á»ƒ há»c tá»‘t mÃ´n hÃ¬nh há»c khÃ´ng gian?
        PhÃ¢n loáº¡i: study_support
        ---
        User: GiÃ¡ vÃ ng hÃ´m nay bao nhiÃªu?
        PhÃ¢n loáº¡i: off_topic
        ---

        **BÃ¢y giá», hÃ£y phÃ¢n loáº¡i lá»‹ch sá»­ chat sau. Chá»‰ tráº£ vá» Má»˜T tá»« duy nháº¥t.**

        **Lá»‹ch sá»­ chat:**
        {{ conversation_history }}

        **PhÃ¢n loáº¡i:**
        """

    # --- TEMPLATES CHO TUTOR AGENT ---

    # Prompt tá»•ng quÃ¡t Ä‘á»‹nh hÃ¬nh vai trÃ² vÃ  tÃ­nh cÃ¡ch
    tutor_master_prompt = """
    Báº¡n lÃ  má»™t Gia sÆ° ToÃ¡n AI, má»™t ngÆ°á»i báº¡n Ä‘á»“ng hÃ nh há»c táº­p thÃ´ng minh, tháº¥u cáº£m vÃ  chuyÃªn nghiá»‡p.
    Vai trÃ² cá»§a báº¡n lÃ  pháº£n há»“i láº¡i há»c sinh má»™t cÃ¡ch phÃ¹ há»£p nháº¥t dá»±a trÃªn Ã½ Ä‘á»‹nh cá»§a há».
    LuÃ´n sá»­ dá»¥ng ngÃ´n ngá»¯ tÃ­ch cá»±c, khuyáº¿n khÃ­ch vÃ  thÃ¢n thiá»‡n. LuÃ´n tráº£ lá»i báº±ng tiáº¿ng Viá»‡t.
    """

    # Prompt cho intent 'greeting_social'
    greeting_template = """
    {{ master_prompt }}

    **Bá»‘i cáº£nh:** Há»c sinh Ä‘ang báº¯t Ä‘áº§u cuá»™c trÃ² chuyá»‡n hoáº·c nÃ³i nhá»¯ng cÃ¢u xÃ£ giao (chÃ o há»i, cáº£m Æ¡n).
    **Nhiá»‡m vá»¥:** HÃ£y pháº£n há»“i láº¡i má»™t cÃ¡ch thÃ¢n thiá»‡n, tá»± nhiÃªn vÃ  má»i gá»i há» báº¯t Ä‘áº§u buá»•i há»c.

    **Lá»‹ch sá»­ chat gáº§n Ä‘Ã¢y:**
    {{ conversation_history }}

    **Lá»i chÃ o thÃ¢n thiá»‡n cá»§a báº¡n:**
    """

    # Prompt cho intent 'expression_of_stress'
    stress_template = """
    {{ master_prompt }}

    **Bá»‘i cáº£nh:** Há»c sinh Ä‘ang thá»ƒ hiá»‡n sá»± cÄƒng tháº³ng, má»‡t má»i hoáº·c náº£n lÃ²ng vá» viá»‡c há»c.
    **NHIá»†M Vá»¤ Cá»°C Ká»² QUAN TRá»ŒNG:**
    1.  **Äá»“ng cáº£m:** Thá»ƒ hiá»‡n ráº±ng báº¡n hiá»ƒu cáº£m giÃ¡c cá»§a há».
    2.  **BÃ¬nh thÆ°á»ng hÃ³a:** Cho há» biáº¿t ráº±ng cáº£m giÃ¡c nÃ y lÃ  bÃ¬nh thÆ°á»ng.
    3.  **Gá»£i Ã½ giáº£i phÃ¡p AN TOÃ€N:** Äá» xuáº¥t nhá»¯ng hÃ nh Ä‘á»™ng Ä‘Æ¡n giáº£n nhÆ° nghá»‰ ngÆ¡i, hÃ­t thá»Ÿ sÃ¢u.
    4.  **TUYá»†T Äá»I KHÃ”NG:** ÄÃ³ng vai chuyÃªn gia tÃ¢m lÃ½, khÃ´ng Ä‘Æ°a ra lá»i khuyÃªn phá»©c táº¡p.

    **Lá»‹ch sá»­ chat gáº§n Ä‘Ã¢y:**
    {{ conversation_history }}

    **Lá»i Ä‘á»™ng viÃªn an toÃ n vÃ  tháº¥u cáº£m cá»§a báº¡n:**
    """

    # Prompt cho intent 'study_support'
    support_template = """
    {{ master_prompt }}

    **Bá»‘i cáº£nh:** Há»c sinh Ä‘ang há»i vá» phÆ°Æ¡ng phÃ¡p há»c táº­p, cÃ¡ch Ä‘á»ƒ tiáº¿n bá»™ hoáº·c tÃ¬m kiáº¿m Ä‘á»™ng lá»±c.
    **Nhiá»‡m vá»¥:** HÃ£y Ä‘Æ°a ra nhá»¯ng lá»i khuyÃªn chung, há»¯u Ã­ch vÃ  mang tÃ­nh Ä‘á»™ng viÃªn vá» viá»‡c há»c ToÃ¡n. Báº¡n cÃ³ thá»ƒ gá»£i Ã½ vá» cÃ¡c chá»©c nÄƒng cá»§a mÃ¬nh (giáº£i bÃ i táº­p, táº¡o luyá»‡n táº­p,...).

    **Lá»‹ch sá»­ chat gáº§n Ä‘Ã¢y:**
    {{ conversation_history }}

    **Lá»i khuyÃªn vÃ  há»— trá»£ cá»§a báº¡n:**
    """

    # Prompt cho intent 'off_topic'
    off_topic_template = """
    {{ master_prompt }}

    **Bá»‘i cáº£nh:** Há»c sinh Ä‘ang há»i má»™t cÃ¢u hoÃ n toÃ n khÃ´ng liÃªn quan Ä‘áº¿n toÃ¡n há»c hoáº·c há»c táº­p.
    **Nhiá»‡m vá»¥:** HÃ£y lá»‹ch sá»± tá»« chá»‘i tráº£ lá»i vÃ  nháº¹ nhÃ ng hÆ°á»›ng cuá»™c trÃ² chuyá»‡n quay trá»Ÿ láº¡i chá»§ Ä‘á» chÃ­nh lÃ  há»c ToÃ¡n.

    **Lá»‹ch sá»­ chat gáº§n Ä‘Ã¢y:**
    {{ conversation_history }}

    **Lá»i tá»« chá»‘i khÃ©o lÃ©o cá»§a báº¡n:**
    """

    # Create prompt builders
    informer_prompt_builder = PromptBuilder(template=informer_template, required_variables=["documents", "query", "conversation_history"])
    practice_prompt_builder = PromptBuilder(template=practice_template, required_variables=["student_weakness", "video_cheatsheet_json"])
    insight_prompt_builder = PromptBuilder(template=insight_template, required_variables=["conversation_history"])
    verifier_prompt_builder = PromptBuilder(template=verifier_template, required_variables=["query", "informer_answer"])
    intent_prompt_builder = PromptBuilder(template=intent_template, required_variables=["conversation_history"])
    
    greeting_prompt_builder = PromptBuilder(template=greeting_template, required_variables=["master_prompt", "conversation_history"])
    stress_prompt_builder = PromptBuilder(template=stress_template, required_variables=["master_prompt", "conversation_history"])
    support_prompt_builder = PromptBuilder(template=support_template, required_variables=["master_prompt", "conversation_history"])
    off_topic_prompt_builder = PromptBuilder(template=off_topic_template, required_variables=["master_prompt", "conversation_history"])
    
    # Create generator
    generator = CustomGoogleAIGenerator(api_key=os.getenv("GOOGLE_API_KEY"))
    
    return {
        "informer_prompt_builder": informer_prompt_builder,
        "generator": generator,
        "practice_prompt_builder": practice_prompt_builder,
        "insight_prompt_builder": insight_prompt_builder,
        "verifier_prompt_builder": verifier_prompt_builder,
        "intent_prompt_builder": intent_prompt_builder,
        "videos_data": videos_data,
        "document_store": document_store,
        "tutor_master_prompt": tutor_master_prompt,
        "greeting_prompt_builder": greeting_prompt_builder,
        "stress_prompt_builder": stress_prompt_builder,
        "support_prompt_builder": support_prompt_builder,
        "off_topic_prompt_builder": off_topic_prompt_builder,
        "retriever": retriever,
        "text_embedder": text_embedder,
        "whisper_model": whisper_model
    }

def transcribe_audio(audio_file, whisper_model: WhisperModel) -> str:
    """
    Nháº­n audio file tá»« st.audio_input vÃ  chuyá»ƒn Ä‘á»•i thÃ nh vÄƒn báº£n báº±ng Faster Whisper.
    PhiÃªn báº£n Ä‘Æ°á»£c cáº­p nháº­t cho mÃ´i trÆ°á»ng deployment.
    """
    if not audio_file:
        return ""
        
    tmp_file_path = ""
    try:
        # Äá»c audio file tá»« st.audio_input (UploadedFile object)
        audio_bytes = audio_file.read()
        
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmpfile:
            tmpfile.write(audio_bytes)
            tmp_file_path = tmpfile.name
        
        print(f"DEBUG: [Whisper] Audio saved to temp file: {tmp_file_path}")
        
        print(f"DEBUG: [Whisper] Transcribing audio from: {tmp_file_path}")
        segments, info = whisper_model.transcribe(tmp_file_path, beam_size=5, language="vi")

        print(f"DEBUG: [Whisper] Detected language: {info.language} with probability {info.language_probability}")
        
        transcribed_text = " ".join(segment.text for segment in segments)
        print(f"DEBUG: [Whisper] Transcribed text: '{transcribed_text}'")
        return transcribed_text.strip()
            
    except Exception as e:
        st.error(f"Lá»—i khi xá»­ lÃ½ giá»ng nÃ³i: {e}")
        return ""
    finally:
        if tmp_file_path and os.path.exists(tmp_file_path):
            os.remove(tmp_file_path)
            print(f"DEBUG: [Whisper] Cleaned up temp file: {tmp_file_path}")


def classify_intent(conversation_history: str, resources: Dict) -> str:
    """PhÃ¢n loáº¡i Ã½ Ä‘á»‹nh ngÆ°á»i dÃ¹ng"""
    valid_intents = ['greeting_social', 'math_question', 'request_for_practice', 'expression_of_stress', 'study_support', 'off_topic']
    
    try:
        prompt_builder = resources["intent_prompt_builder"]
        
        prompt_text = prompt_builder.run(conversation_history=conversation_history)["prompt"]
        
        result = resources["generator"].run(prompt_parts=[prompt_text])
        intent = result["replies"][0].strip().lower()
        
        user_input_debug = "N/A"
        if 'User: ' in conversation_history: 
            lines = conversation_history.split('\n')
            for line in reversed(lines):
                if line.strip().startswith('User: '): 
                    user_input_debug = line.replace('User: ', '').strip()
                    break
        
        print(f"DEBUG - User input: {user_input_debug}")
        print(f"DEBUG - Classified intent: {intent}")
        
        if intent not in valid_intents:
            math_keywords = ['giáº£i', 'tÃ­nh', 'phÆ°Æ¡ng trÃ¬nh', 'bÃ i táº­p', 'toÃ¡n', 'xÃ¡c suáº¥t', 'thá»‘ng kÃª', 'hÃ¬nh há»c', 'Ä‘áº¡i sá»‘']
            
            user_input_for_fallback = "N/A"
            if 'User: ' in conversation_history:
                lines = conversation_history.split('\n')
                for line in reversed(lines):
                    if line.strip().startswith('User: '):
                        user_input_for_fallback = line.replace('User: ', '').strip()
                        break
            
            if any(keyword in user_input_for_fallback.lower() for keyword in math_keywords):
                intent = 'math_question'
            else:
                intent = 'greeting_social'
        
        return intent
    except Exception as e:
        print(f"DEBUG - Intent classification error: {e}")
        return 'greeting_social'

def informer_agent(query: str, conversation_history_str: str, resources: Dict) -> str:
    """Agent giáº£i toÃ¡n dá»±a trÃªn RAG"""
    try:
        result = resources["informer_pipeline"].run({
            "text_embedder": {"text": query},
            "prompt_builder": {"query": query, "conversation_history": conversation_history_str}
        })
        return result["generator"]["replies"][0]
    except:
        return "Xin lá»—i, tÃ´i khÃ´ng thá»ƒ giáº£i bÃ i nÃ y lÃºc nÃ y."

def verifier_agent(query: str, informer_answer: str, resources: Dict) -> Dict:
    """Agent kiá»ƒm tra tÃ­nh Ä‘Ãºng Ä‘áº¯n"""
    try:
        prompt_text = resources["verifier_prompt_builder"].run(query=query, informer_answer=informer_answer)["prompt"]
        result = resources["generator"].run(prompt_parts=[prompt_text])
        llm_reply_string = result["replies"][0]

        json_match = re.search(r"\{.*\}", llm_reply_string, re.DOTALL)
        if json_match:
            return json.loads(json_match.group(0))
        else:
            return {"is_correct": True, "correction_suggestion": "Lá»—i parse verifier"}
    except Exception as e:
        print(f"ERROR: [Verifier Agent] Lá»—i: {e}")
        return {"is_correct": True, "correction_suggestion": ""}

def insight_agent(conversation_history: str, resources: Dict) -> Dict:
    """Agent phÃ¢n tÃ­ch Ä‘iá»ƒm yáº¿u, vá»›i logic trÃ­ch xuáº¥t JSON thÃ´ng minh."""
    try:
        prompt_builder = resources["insight_prompt_builder"]
        prompt_text = prompt_builder.run(conversation_history=conversation_history)["prompt"]
        
        print("\n" + "="*50)
        print(prompt_text)
        print("="*50 + "\n")

        result = resources["generator"].run(prompt_parts=[prompt_text])
        llm_reply = result["replies"][0]

        json_match = re.search(r"\{.*\}", llm_reply, re.DOTALL)
        
        if json_match:
            json_string = json_match.group(0)
            return json.loads(json_string)
        else:
            return {"misunderstood_concepts": [], "sentiment": "neutral"}

    except json.JSONDecodeError as e:
        return {"misunderstood_concepts": [], "sentiment": "neutral"}
    except Exception as e:
        return {"misunderstood_concepts": [], "sentiment": "neutral"}

def practice_agent(student_weakness: str, resources: Dict) -> str:
    """Agent táº¡o bÃ i táº­p"""
    try:
        video_cheatsheet = []
        for video in resources["videos_data"]:
            video_cheatsheet.append({
                "title": video["title"],
                "keywords": video["keywords"],
                "summary": video["summary_for_llm"]
            })
        
        video_json = json.dumps(video_cheatsheet, ensure_ascii=False)
        prompt_text = resources["practice_prompt_builder"].run(
            student_weakness=student_weakness,
            video_cheatsheet_json=video_json
        )["prompt"]
        
        result = resources["generator"].run(prompt_parts=[prompt_text])
        return result["replies"][0]
    except:
        return "Xin lá»—i, tÃ´i khÃ´ng thá»ƒ táº¡o bÃ i táº­p lÃºc nÃ y."

def problem_solving_engine(
    query_text: str, 
    query_image: bytes, 
    conversation_history_str: str, 
    resources: Dict
) -> str:
    """
    Cá»— mÃ¡y giáº£i quyáº¿t váº¥n Ä‘á» Ä‘a nÄƒng, TÃI Sá»¬ Dá»¤NG informer_prompt_builder.
    """
    print("DEBUG: Multimodal Problem-Solving Engine activated.")
    
    try:
        extracted_text_from_image = ""
        if query_image:
            print("DEBUG: [Stage 1] Image detected. Calling Gemini for OCR...")
            try:
                ocr_prompt_parts = [
                    "Báº¡n lÃ  má»™t há»‡ thá»‘ng OCR toÃ¡n há»c siÃªu chÃ­nh xÃ¡c. HÃ£y Ä‘á»c vÃ  trÃ­ch xuáº¥t toÃ n bá»™ vÄƒn báº£n tá»« hÃ¬nh áº£nh sau Ä‘Ã¢y. Chá»‰ tráº£ vá» pháº§n vÄƒn báº£n Ä‘Æ°á»£c trÃ­ch xuáº¥t.", 
                    query_image
                ]
                ocr_result = resources["generator"].run(prompt_parts=ocr_prompt_parts)
                extracted_text_from_image = ocr_result["replies"][0]
                print(f"DEBUG: [Stage 1] Text extracted from image: '{extracted_text_from_image}'")
            except Exception as e:
                print(f"ERROR: [Stage 1] OCR failed: {e}")
                extracted_text_from_image = "KhÃ´ng thá»ƒ Ä‘á»c Ä‘Æ°á»£c ná»™i dung tá»« hÃ¬nh áº£nh."

        full_query_text = (query_text + " " + extracted_text_from_image).strip()
        print(f"DEBUG: [Stage 1.5] Full query text: '{full_query_text}'")

        context_docs = []
        if full_query_text:
            try:
                print("DEBUG: [Stage 2] Starting RAG retrieval...")
                embedding = resources["text_embedder"].run(text=full_query_text)["embedding"]
                print("DEBUG: [Stage 2] Embedding created successfully")
                context_docs = resources["retriever"].run(query_embedding=embedding)["documents"]
                print(f"DEBUG: [Stage 2] Retrieved {len(context_docs)} documents")
            except Exception as e:
                print(f"ERROR: [Stage 2] RAG retrieval failed: {e}")
                context_docs = []

        print("DEBUG: [Stage 3] Building final prompt...")
        
        try:
            informer_prompt_builder = resources["informer_prompt_builder"]
            print("DEBUG: [Stage 3a] Got informer_prompt_builder")
            
            text_prompt_result = informer_prompt_builder.run(
                query=query_text if query_text else "Giáº£i bÃ i toÃ¡n trong hÃ¬nh.",
                conversation_history=conversation_history_str,
                documents=context_docs
            )
            print("DEBUG: [Stage 3a] Prompt builder ran successfully")
            
            text_part = text_prompt_result["prompt"]
            print(f"DEBUG: [Stage 3a] Generated text prompt length: {len(text_part)} chars")
            
        except Exception as e:
            print(f"ERROR: [Stage 3a] Prompt building failed: {e}")
            # Fallback to simple prompt
            text_part = f"""Báº¡n lÃ  gia sÆ° toÃ¡n AI. HÃ£y giáº£i bÃ i toÃ¡n sau:

                CÃ¢u há»i: {query_text if query_text else "Giáº£i bÃ i toÃ¡n trong hÃ¬nh"}
                Ná»™i dung tá»« hÃ¬nh: {extracted_text_from_image}

                Lá»‹ch sá»­: {conversation_history_str}

                HÃ£y tráº£ lá»i chi tiáº¿t báº±ng tiáº¿ng Viá»‡t:"""

        final_prompt_parts = [text_part]
        
        if query_image:
            final_prompt_parts.append("\n**HÃ¬nh áº£nh Ä‘Ã­nh kÃ¨m:**")
            final_prompt_parts.append(query_image)
            
        print(f"DEBUG: [Stage 3b] Final prompt parts count: {len(final_prompt_parts)}")
            
        print("DEBUG: [Stage 4] Calling Gemini for final answer...")
        try:
            final_result = resources["generator"].run(prompt_parts=final_prompt_parts)
            informer_answer = final_result["replies"][0]
            print(f"DEBUG: [Stage 4] Got answer, length: {len(informer_answer)} chars")
        except Exception as e:
            print(f"ERROR: [Stage 4] Gemini call failed: {e}")
            return f"Xin lá»—i, tÃ´i khÃ´ng thá»ƒ xá»­ lÃ½ cÃ¢u há»i nÃ y lÃºc nÃ y. Lá»—i: {str(e)}"

        try:
            print("DEBUG: [Stage 5] Starting verification...")
            verification_query = full_query_text if full_query_text else "PhÃ¢n tÃ­ch bÃ i toÃ¡n trong hÃ¬nh áº£nh"
            verification = verifier_agent(verification_query, informer_answer, resources)
            print(f"DEBUG: [Stage 5] Verification result: {verification}")
            
            if verification.get("is_correct", True):
                return informer_answer
            else:
                correction = verification.get("correction_suggestion", "")
                return f"ğŸ” TÃ´i Ä‘Ã£ xem xÃ©t láº¡i vÃ  tháº¥y cÃ³ má»™t chÃºt chÆ°a chÃ­nh xÃ¡c. {correction}"
        except Exception as e:
            print(f"ERROR: [Stage 5] Verification failed: {e}")
            return informer_answer

    except Exception as e:
        print(f"ERROR: [Problem-Solving Engine] Critical error: {str(e)}")
        import traceback
        print(f"ERROR: [Problem-Solving Engine] Traceback: {traceback.format_exc()}")
        return f"Xin lá»—i, Ä‘Ã£ cÃ³ lá»—i nghiÃªm trá»ng khi xá»­ lÃ½ yÃªu cáº§u: {str(e)}"


def tutor_agent_response(user_input: str, intent: str, conversation_history_str: str, resources: Dict, supabase: Client, user_id: str, display_name: str) -> str:
    """
    Agent chÃ­nh, bÃ¢y giá» CHá»ˆ xá»­ lÃ½ cÃ¡c intent giao tiáº¿p.
    CÃ¡c cÃ¢u há»i toÃ¡n há»c Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½ bá»Ÿi problem_solving_engine.
    """
    print(f"DEBUG: Tutor Agent is handling a communication intent: '{intent}'")
    
    if intent == "greeting_social":
        prompt_builder = resources["greeting_prompt_builder"]
    elif intent == "expression_of_stress":
        prompt_builder = resources["stress_prompt_builder"]
    elif intent == "study_support":
        prompt_builder = resources["support_prompt_builder"]
    elif intent == "request_for_practice":
        print("DEBUG: Tutor Agent is triggering the Practice Flow.")
        insights = insight_agent(conversation_history_str, resources)
        if insights and insights.get("misunderstood_concepts"):
            weakness = insights["misunderstood_concepts"][0]
            return practice_agent(weakness, resources)
        else:
            return practice_agent("cÃ¡c chá»§ Ä‘á» toÃ¡n lá»›p 9 tá»•ng quÃ¡t", resources)
    else: 
        prompt_builder = resources["off_topic_prompt_builder"]
        
    try:
        prompt_text = prompt_builder.run(
            master_prompt=resources["tutor_master_prompt"],
            conversation_history=conversation_history_str
        )["prompt"]
        
        result = resources["generator"].run(prompt_parts=[prompt_text])
        return result["replies"][0]
    except Exception as e:
        print(f"ERROR: Could not generate response for intent '{intent}': {e}")
        return "Ráº¥t xin lá»—i, tÃ´i Ä‘ang gáº·p má»™t chÃºt sá»± cá»‘."

def render_chat_message(content: str, is_user: bool, key: str, image: bytes = None):
    """Render tin nháº¯n chat, cÃ³ thá»ƒ kÃ¨m áº£nh."""
    css_class = "user-message" if is_user else "bot-message"
    
    if image:
        st.image(image, width=250)
        
    if content:
        # Xá»­ lÃ½ format text Ä‘á»ƒ trÃ¡nh hiá»ƒn thá»‹ rá»i ráº¡c
        cleaned_content = content.strip()
        
        # TÃ¡ch thÃ nh cÃ¡c paragraph dá»±a trÃªn line breaks kÃ©p
        paragraphs = cleaned_content.split('\n\n')
        formatted_paragraphs = []
        
        for paragraph in paragraphs:
            if paragraph.strip():
                # Xá»­ lÃ½ tá»«ng paragraph
                lines = paragraph.split('\n')
                # GhÃ©p cÃ¡c dÃ²ng trong cÃ¹ng paragraph láº¡i vá»›i nhau
                # Chá»‰ thÃªm space náº¿u dÃ²ng khÃ´ng káº¿t thÃºc báº±ng dáº¥u cÃ¢u
                formatted_lines = []
                for line in lines:
                    line = line.strip()
                    if line:
                        # Náº¿u dÃ²ng káº¿t thÃºc báº±ng dáº¥u cÃ¢u, khÃ´ng thÃªm space
                        if line.endswith(('.', ',', ':', ';', '!', '?')):
                            formatted_lines.append(line)
                        else:
                            # Náº¿u khÃ´ng káº¿t thÃºc báº±ng dáº¥u cÃ¢u, thÃªm space Ä‘á»ƒ ghÃ©p vá»›i dÃ²ng tiáº¿p theo
                            formatted_lines.append(line + ' ')
                
                # GhÃ©p cÃ¡c dÃ²ng trong paragraph
                paragraph_text = ''.join(formatted_lines)
                # Xá»­ lÃ½ khoáº£ng tráº¯ng thá»«a
                paragraph_text = ' '.join(paragraph_text.split())
                formatted_paragraphs.append(paragraph_text)
        
        # GhÃ©p cÃ¡c paragraph láº¡i vá»›i line break
        final_content = '\n\n'.join(formatted_paragraphs)
        
        # Sá»­ dá»¥ng markdown Ä‘á»ƒ render vá»›i format Ä‘Ãºng
        st.markdown(f'<div class="{css_class}">{final_content}</div>', unsafe_allow_html=True)

def should_trigger_proactive_practice(conversation_history: List[Dict[str, str]]) -> bool:
    """
    Kiá»ƒm tra xem cÃ³ nÃªn kÃ­ch hoáº¡t luá»“ng luyá»‡n táº­p chá»§ Ä‘á»™ng khÃ´ng
    báº±ng cÃ¡ch Ä‘áº¿m sá»‘ lÆ°á»£ng intent 'math_question' Ä‘Ã£ Ä‘Æ°á»£c lÆ°u.
    """
    print("\n--- DEBUG: [should_trigger_proactive_practice] Báº¯t Ä‘áº§u kiá»ƒm tra Ä‘iá»u kiá»‡n ---")

    if len(conversation_history) < 6:
        print("DEBUG: KÃ­ch hoáº¡t = False. LÃ½ do: Lá»‹ch sá»­ chat quÃ¡ ngáº¯n.")
        return False
    
    user_intents = [msg['intent'] for msg in conversation_history if msg['role'] == 'user'][-3:]
    
    if len(user_intents) < 3:
        print("DEBUG: KÃ­ch hoáº¡t = False. LÃ½ do: KhÃ´ng cÃ³ Ä‘á»§ 3 lÆ°á»£t tÆ°Æ¡ng tÃ¡c tá»« ngÆ°á»i dÃ¹ng.")
        return False

    print(f"DEBUG: PhÃ¢n tÃ­ch 3 intent gáº§n nháº¥t cá»§a ngÆ°á»i dÃ¹ng: {user_intents}")
    
    math_question_count = user_intents.count('math_question')
    
    should_trigger = math_question_count >= 2

    print(f"DEBUG: Tá»•ng sá»‘ intent 'math_question': {math_question_count}/3.")
    print(f"DEBUG: KÃ­ch hoáº¡t = {should_trigger}.")
    print("--- Káº¾T THÃšC KIá»‚M TRA ---")
    
    return should_trigger


def show_typing_indicator():
    """Hiá»ƒn thá»‹ indicator khi bot Ä‘ang suy nghÄ©"""
    return st.markdown('''
        <div class="typing-indicator">
            <span style="margin-right: 10px;">ğŸ¤– Äang suy nghÄ© ...</span>
            <div class="typing-dots">
                <div class="typing-dot"></div>
                <div class="typing-dot"></div>
                <div class="typing-dot"></div>
            </div>
        </div>
    ''', unsafe_allow_html=True)

def handle_modern_auth(supabase: Client):
    """Xá»­ lÃ½ authentication vá»›i UI hiá»‡n Ä‘áº¡i"""
    
    # Kiá»ƒm tra session
    try:
        session = supabase.auth.get_session()
        if session and session.user and session.user.email_confirmed_at:
            if "user" not in st.session_state:
                st.session_state.user = session.user
    except:
        if "user" in st.session_state:
            del st.session_state.user
    
    # Náº¿u chÆ°a Ä‘Äƒng nháº­p
    if "user" not in st.session_state or st.session_state.user is None:
        
        # Welcome message
        st.markdown('''
            <div class="welcome-message">
                <h1>ğŸ¤– ChÃ o má»«ng Ä‘áº¿n vá»›i Gia sÆ° AI</h1>
                <p style="font-size: 1.2em; margin: 1rem 0;">
                    Há»‡ thá»‘ng gia sÆ° ToÃ¡n thÃ´ng minh vá»›i 5 AI Agent chuyÃªn nghiá»‡p
                </p>
                <p style="opacity: 0.9;">
                    ÄÄƒng nháº­p Ä‘á»ƒ báº¯t Ä‘áº§u hÃ nh trÃ¬nh há»c táº­p cÃ¡ nhÃ¢n hÃ³a
                </p>
            </div>
        ''', unsafe_allow_html=True)
        
        # Auth tabs
        tab1, tab2 = st.tabs(["ğŸ”‘ ÄÄƒng nháº­p", "ğŸ“ ÄÄƒng kÃ½"])
        
        with tab1:
            with st.form("login_form"):
                st.subheader("ÄÄƒng nháº­p tÃ i khoáº£n")
                email = st.text_input("ğŸ“§ Email", placeholder="example@email.com")
                password = st.text_input("ğŸ”’ Máº­t kháº©u", type="password")
                login_btn = st.form_submit_button("ÄÄƒng nháº­p", use_container_width=True)
                
                if login_btn:
                    if email and password:
                        try:
                            response = supabase.auth.sign_in_with_password({"email": email, "password": password})
                            if response.user and response.user.email_confirmed_at:
                                st.session_state.user = response.user
                                st.success("âœ… ÄÄƒng nháº­p thÃ nh cÃ´ng!")
                                time.sleep(1)
                                st.rerun()
                            else:
                                st.warning("âš ï¸ Vui lÃ²ng xÃ¡c thá»±c email trÆ°á»›c khi Ä‘Äƒng nháº­p!")
                        except Exception as e:
                            if "invalid login credentials" in str(e).lower():
                                st.error("âŒ Email hoáº·c máº­t kháº©u khÃ´ng Ä‘Ãºng")
                            else:
                                st.error(f"âŒ Lá»—i Ä‘Äƒng nháº­p: {str(e)}")
                    else:
                        st.warning("âš ï¸ Vui lÃ²ng nháº­p Ä‘áº§y Ä‘á»§ thÃ´ng tin")
        
        with tab2:
            with st.form("register_form"):
                st.subheader("Táº¡o tÃ i khoáº£n má»›i")
                display_name = st.text_input("ğŸ‘¤ TÃªn cá»§a báº¡n", placeholder="Nguyá»…n VÄƒn A")
                new_email = st.text_input("ğŸ“§ Email", placeholder="example@email.com")
                new_password = st.text_input("ğŸ”’ Máº­t kháº©u", type="password")
                register_btn = st.form_submit_button("ÄÄƒng kÃ½", use_container_width=True)
                
                if register_btn:
                    if display_name and new_email and new_password:
                        try:
                            # --- THAY Äá»”I 3: Gá»¬I KÃˆM TÃŠN TRONG OPTIONS ---
                            response = supabase.auth.sign_up({
                                "email": new_email, 
                                "password": new_password,
                                "options": {
                                    "data": {
                                        "display_name": display_name
                                    }
                                }
                            })
                            if response.user:
                                st.success("ğŸ‰ ÄÄƒng kÃ½ thÃ nh cÃ´ng!")
                                st.info("ğŸ“§ Vui lÃ²ng kiá»ƒm tra email Ä‘á»ƒ xÃ¡c thá»±c tÃ i khoáº£n")
                        except Exception as e:
                            if "already registered" in str(e).lower():
                                st.error("âŒ Email Ä‘Ã£ Ä‘Æ°á»£c Ä‘Äƒng kÃ½")
                            else:
                                st.error(f"âŒ Lá»—i Ä‘Äƒng kÃ½: {str(e)}")
                    else:
                        st.warning("âš ï¸ Vui lÃ²ng nháº­p Ä‘áº§y Ä‘á»§ TÃªn, Email vÃ  Máº­t kháº©u")
        
        # Feature showcase
        st.subheader("ğŸš€ TÃ­nh nÄƒng ná»•i báº­t")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown('''
                <div class="feature-card">
                    <h3>ğŸ§  5 AI Agent thÃ´ng minh</h3>
                    <p>Há»‡ thá»‘ng Ä‘a tÃ¡c nhÃ¢n chuyÃªn nghiá»‡p cho tráº£i nghiá»‡m há»c táº­p tá»‘i Æ°u</p>
                </div>
            ''', unsafe_allow_html=True)
            
            st.markdown('''
                <div class="feature-card">
                    <h3>ğŸ“š Dá»±a trÃªn SGK chÃ­nh thá»©c</h3>
                    <p>Ná»™i dung chuáº©n theo chÆ°Æ¡ng trÃ¬nh ToÃ¡n lá»›p 9</p>
                </div>
            ''', unsafe_allow_html=True)
        
        with col2:
            st.markdown('''
                <div class="feature-card">
                    <h3>ğŸ¯ Há»c táº­p cÃ¡ nhÃ¢n hÃ³a</h3>
                    <p>PhÃ¢n tÃ­ch Ä‘iá»ƒm yáº¿u vÃ  Ä‘á» xuáº¥t bÃ i táº­p phÃ¹ há»£p</p>
                </div>
            ''', unsafe_allow_html=True)
            
            st.markdown('''
                <div class="feature-card">
                    <h3>ğŸ¥ Video bÃ i giáº£ng</h3>
                    <p>Kho video phong phÃº vá»›i lá»i giáº£i chi tiáº¿t</p>
                </div>
            ''', unsafe_allow_html=True)
        
        return False
    
    return True

def main():
    """HÃ m chÃ­nh cá»§a á»©ng dá»¥ng"""
    
    # Khá»Ÿi táº¡o Supabase
    supabase = init_supabase_client()
    
    if not handle_modern_auth(supabase):
        return
    
    # Náº¿u Ä‘Ã£ Ä‘Äƒng nháº­p, láº¥y thÃ´ng tin user
    user = st.session_state.user
    user_id = user.id

    display_name = user.user_metadata.get("display_name", user.email)
    
    with st.spinner("ğŸš€ Äang khá»Ÿi táº¡o há»‡ thá»‘ng AI..."):
        resources = load_resources()
    
    # --- Giao diá»‡n chÃ­nh sau khi Ä‘Äƒng nháº­p ---
    
    # Header
    st.markdown(f'''
        <div style="text-align: center; padding: 1rem; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 15px; margin-bottom: 1rem; color: white; box-shadow: 0 8px 32px rgba(0,0,0,0.1);">
            <h1>ğŸ¤– Gia sÆ° ToÃ¡n AI</h1>
            <p class="status-online">â— Online - Sáºµn sÃ ng há»— trá»£ {display_name}</p>
        </div>
    ''', unsafe_allow_html=True)
    
    # Khá»Ÿi táº¡o session state cho cuá»™c trÃ² chuyá»‡n
    if "messages" not in st.session_state:
        st.session_state.messages = []
        # ThÃªm tin nháº¯n chÃ o má»«ng Ä‘áº§u tiÃªn
        welcome_msg = "Xin chÃ o! TÃ´i lÃ  gia sÆ° AI cá»§a báº¡n ğŸ˜Š. HÃ´m nay chÃºng ta cÃ¹ng há»c ToÃ¡n nhÃ©!"
        st.session_state.messages.append({"role": "assistant", "content": welcome_msg, "intent": "greeting_social"})

    # Khá»Ÿi táº¡o session state Ä‘á»ƒ theo dÃµi audio Ä‘Ã£ xá»­ lÃ½
    if "processed_audio_ids" not in st.session_state:
        st.session_state.processed_audio_ids = set()

    # Container Ä‘á»ƒ chá»©a cÃ¡c tin nháº¯n chat
    chat_placeholder = st.container()
    with chat_placeholder:
        for i, msg_data in enumerate(st.session_state.messages):
            is_user = msg_data["role"] == "user"
            # Sá»­ dá»¥ng hÃ m render tÃ¹y chá»‰nh
            render_chat_message(msg_data["content"], is_user, key=f"msg_{i}")

    # Audio input section with better error handling
    st.markdown("#### Hoáº·c ghi Ã¢m giá»ng nÃ³i:")
    
    # Check if running in secure context for microphone access
    audio_input = None
    try:
        # Use Streamlit's built-in audio_input which is more stable
        audio_input = st.audio_input("ğŸ¤ Nháº¥n Ä‘á»ƒ ghi Ã¢m", help="Ghi Ã¢m cÃ¢u há»i cá»§a báº¡n báº±ng tiáº¿ng Viá»‡t")
    except Exception as e:
        st.warning("âš ï¸ KhÃ´ng thá»ƒ truy cáº­p microphone. Vui lÃ²ng sá»­ dá»¥ng form nháº­p text bÃªn dÆ°á»›i.")
        print(f"DEBUG: Audio input error: {e}")

    # 2. Form Nháº­p liá»‡u cho Text vÃ  áº¢nh
    with st.form(key="chat_form", clear_on_submit=True):
        # Chia layout
        col1, col2 = st.columns([1, 4])
        with col1:
            uploaded_image = st.file_uploader("ÄÃ­nh kÃ¨m áº£nh", type=["png", "jpg", "jpeg"], label_visibility="collapsed")
        with col2:
            user_text = st.text_input("Nháº­p cÃ¢u há»i cá»§a báº¡n...", placeholder="Nháº­p cÃ¢u há»i hoáº·c mÃ´ táº£ cho áº£nh...", label_visibility="collapsed")
        
        submit_button = st.form_submit_button(label="Gá»­i")

    final_user_text = ""
    final_image_data = None

    # Handle audio input if available - vá»›i logic trÃ¡nh xá»­ lÃ½ láº·p láº¡i
    if audio_input is not None:
        # Táº¡o unique ID cho audio file dá»±a trÃªn file_id vÃ  size
        audio_id = f"{audio_input.file_id}_{audio_input.size}" if hasattr(audio_input, 'file_id') and hasattr(audio_input, 'size') else f"{id(audio_input)}_{len(audio_input.getvalue())}"
        
        # Chá»‰ xá»­ lÃ½ náº¿u audio nÃ y chÆ°a Ä‘Æ°á»£c xá»­ lÃ½
        if audio_id not in st.session_state.processed_audio_ids:
            with st.spinner("ğŸ§ Äang xá»­ lÃ½ giá»ng nÃ³i..."):
                transcribed_text = transcribe_audio(audio_input, resources["whisper_model"])
                if transcribed_text and transcribed_text.strip() and len(transcribed_text.strip()) > 1:
                    final_user_text = transcribed_text
                    st.success(f"âœ… ÄÃ£ nháº­n diá»‡n: {transcribed_text}")
                    # ÄÃ¡nh dáº¥u audio nÃ y Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½
                    st.session_state.processed_audio_ids.add(audio_id)
                else:
                    st.warning("âš ï¸ KhÃ´ng nháº­n diá»‡n Ä‘Æ°á»£c ná»™i dung. Vui lÃ²ng thá»­ láº¡i hoáº·c sá»­ dá»¥ng text input.")
                    # Váº«n Ä‘Ã¡nh dáº¥u Ä‘á»ƒ trÃ¡nh xá»­ lÃ½ láº¡i
                    st.session_state.processed_audio_ids.add(audio_id)
        else:
            # Audio Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½, khÃ´ng lÃ m gÃ¬ cáº£
            print(f"DEBUG: Audio {audio_id} Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½ trÆ°á»›c Ä‘Ã³, bá» qua.")
    
    # Handle form submission
    elif submit_button:
        final_user_text = user_text
        if uploaded_image:
            final_image_data = uploaded_image.getvalue()

    if final_user_text or final_image_data:
        
        st.session_state.messages.append({
            "role": "user", 
            "content": final_user_text, 
            "image": final_image_data,
            "intent": "unknown"
        })
        with chat_placeholder:
             render_chat_message(final_user_text, is_user=True, image=final_image_data, key=f"user_{len(st.session_state.messages)}")

        history_str_for_llm = "\n".join([f"{msg['role'].capitalize()}: {msg['content']}" for msg in st.session_state.messages[-10:] if msg['content']])
        detected_intent = classify_intent(history_str_for_llm, resources)
        st.session_state.messages[-1]["intent"] = detected_intent
        
        with chat_placeholder:
            typing_indicator_placeholder = show_typing_indicator()

        if final_image_data or detected_intent == "math_question":
            bot_response = problem_solving_engine(
                query_text=final_user_text,
                query_image=final_image_data,
                conversation_history_str=history_str_for_llm,
                resources=resources
            )
        else:
            bot_response = tutor_agent_response(
                user_input=final_user_text, 
                intent=detected_intent,
                conversation_history_str=history_str_for_llm,
                resources=resources,
                supabase=supabase,
                user_id=user_id,
                display_name=display_name
            )
        
        typing_indicator_placeholder.empty()

        st.session_state.messages.append({"role": "assistant", "content": bot_response, "intent": detected_intent, "image": None})
        with chat_placeholder:
            render_chat_message(bot_response, is_user=False, key=f"bot_{len(st.session_state.messages)}")

        if should_trigger_proactive_practice(st.session_state.messages):
    
            with chat_placeholder:
                proactive_typing_placeholder = show_typing_indicator()
            
            try:
                print("\n--- DEBUG: [Proactive Flow] Báº¯t Ä‘áº§u luá»“ng phÃ¢n tÃ­ch vÃ  Ä‘á» xuáº¥t ---")
                
                history_str_for_insight = "\n".join([f"{msg['role'].capitalize()}: {msg['content']}" for msg in st.session_state.messages[-10:]])
                
                # Gá»i Insight Agent
                print("DEBUG: [Proactive Flow] Gá»i Insight Agent...")
                insights = insight_agent(history_str_for_insight, resources)
                print(f"DEBUG: [Proactive Flow] Insight Agent tráº£ vá»: {insights}")
                
                if insights and isinstance(insights, dict) and insights.get("misunderstood_concepts"):
                    
                    current_profile = get_user_profile(supabase, user_id)
                    
                    old_concepts = current_profile.get("misunderstood_concepts", []) if current_profile else []
                    
                    new_concepts = insights["misunderstood_concepts"]
                 
                    combined_concepts_set = set(old_concepts) | set(new_concepts)
                    updated_concepts = list(combined_concepts_set)
                    
                    last_weakness = new_concepts[0] if new_concepts else (old_concepts[0] if old_concepts else None)
                    user_email = user.email
                    
                    profile_data_to_save = {
                        "email": user_email, 
                        "misunderstood_concepts": updated_concepts, 
                        "last_weakness": last_weakness,
                        "updated_at": datetime.now().isoformat()
                    }
                    
                    print(f"DEBUG: [Proactive Flow] Dá»¯ liá»‡u cáº­p nháº­t (Ä‘Ã£ cá»™ng dá»“n): {profile_data_to_save}")
                    update_user_profile(supabase, user_id, profile_data_to_save)
                    
                    st.toast("âœ… ÄÃ£ phÃ¢n tÃ­ch vÃ  cáº­p nháº­t há»“ sÆ¡ há»c táº­p!", icon="ğŸ§ ")
                    print(f"DEBUG: [Proactive Flow] PhÃ¡t hiá»‡n Ä‘iá»ƒm yáº¿u: '{last_weakness}'. Gá»i Practice Agent...")
                    
                    practice_response = practice_agent(last_weakness, resources)
                    
                    proactive_msg = f"ğŸ’¡ **PhÃ¢n tÃ­ch nhanh:** Dá»±a trÃªn cÃ¡c cÃ¢u há»i vá»«a rá»“i, tÃ´i nháº­n tháº¥y báº¡n cÃ³ thá»ƒ cáº§n luyá»‡n táº­p thÃªm vá» chá»§ Ä‘á» **'{last_weakness}'**. ÄÃ¢y lÃ  má»™t sá»‘ gá»£i Ã½ cho báº¡n:\n\n{practice_response}"
                    
                    proactive_typing_placeholder.empty()
                    st.session_state.messages.append({"role": "assistant", "content": proactive_msg, "intent": "proactive_suggestion"})
                    
                    with chat_placeholder:
                        render_chat_message(proactive_msg, is_user=False, key=f"proactive_{len(st.session_state.messages)}")
                
                else:
                    print("DEBUG: [Proactive Flow] Insight Agent khÃ´ng tÃ¬m tháº¥y Ä‘iá»ƒm yáº¿u nÃ o cá»¥ thá»ƒ. Bá» qua Ä‘á» xuáº¥t.")
                    proactive_typing_placeholder.empty()

            except Exception as e:
                print(f"ERROR: [Proactive Flow] ÄÃ£ xáº£y ra lá»—i: {str(e)}")
                proactive_typing_placeholder.empty()

        # Rerun Ä‘á»ƒ cáº­p nháº­t giao diá»‡n
        st.rerun()

    # Sidebar vá»›i thÃ´ng tin khi Ä‘Ã£ Ä‘Äƒng nháº­p
    with st.sidebar:
        st.header(f"ğŸ‘¤ ChÃ o, {display_name}")
        st.caption(f"Email: {user.email}")
        
        if st.button("ÄÄƒng xuáº¥t", use_container_width=True):
            supabase.auth.sign_out()
            # XÃ³a cÃ¡c session state liÃªn quan Ä‘áº¿n user
            keys_to_delete = ["user", "messages", "processed_audio_ids"]
            for key in keys_to_delete:
                if key in st.session_state:
                    del st.session_state[key]
            st.success("âœ… ÄÃ£ Ä‘Äƒng xuáº¥t!")
            time.sleep(1)
            st.rerun()
        
        if st.button("ğŸ—‘ï¸ XÃ³a lá»‹ch sá»­ chat", use_container_width=True):
            st.session_state.messages = []
            # CÅ©ng xÃ³a audio Ä‘Ã£ xá»­ lÃ½ Ä‘á»ƒ cÃ³ thá»ƒ ghi Ã¢m láº¡i
            st.session_state.processed_audio_ids = set()
            st.rerun()

if __name__ == "__main__":
    main()